\documentclass[]{elsarticle} %review=doublespace preprint=single 5p=2 column
%%% Begin My package additions %%%%%%%%%%%%%%%%%%%
\usepackage[hyphens]{url}

  \journal{arXiv.org} % Sets Journal name


\usepackage{lineno} % add
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\usepackage{graphicx}
\usepackage{booktabs} % book-quality tables
%%%%%%%%%%%%%%%% end my additions to header

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage[margin=1.0in]{geometry}
\bibliographystyle{elsarticle-harv}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Individualized treatment effect was predicted best by modeling baseline risk in interaction with treatment assignment},
            colorlinks=false,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls

\setcounter{secnumdepth}{5}
% Pandoc toggle for numbering sections (defaults to be off)

% Pandoc citation processing
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
% for Pandoc 2.8 to 2.10.1
\newenvironment{cslreferences}%
  {}%
  {\par}
% For Pandoc 2.11+
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

% Pandoc header
\renewcommand*\familydefault{\sfdefault}
\usepackage{setspace}
\usepackage{amsmath}
\doublespacing
\usepackage{amssymb}
\usepackage{bm}
\usepackage{caption}
\usepackage{booktabs}
\date{}
\newcommand\given[1][]{\:#1\vert\:}
\newcommand{\indep}{\perp \!\!\! \perp}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}



\begin{document}
\begin{frontmatter}

  \title{Individualized treatment effect was predicted best by modeling
baseline risk in interaction with treatment assignment}
    \author[1]{Alexandros Rekkas}
  
    \author[1]{Peter R. Rijnbeek}
  
    \author[2]{David M. Kent}
  
    \author[3]{Ewout W. Steyerberg}
  
    \author[4]{David van Klaveren}
  
      \address[1]{Department of Medical Informatics, Erasmus Medical
Center, Rotterdam, The Netherlands}
    \address[2]{Predictive Analytics and Comparative Effectiveness
Center, Institute for Clinical Research and Health Policy Studies, Tufts
Medical Center, Boston, Massachusetts, USA}
    \address[3]{Department of Biomedical Data Sciences, Leiden
University Medical Center, Leiden, The Netherlands}
    \address[4]{Department of Public Health, Erasmus Medical Center,
Rotterdam, The Netherlands}
    
  \begin{abstract}
  \textbf{Objective}: To compare different risk-based methods for
  optimal prediction of individualized treatment effects. \textbf{Study
  Design and Setting}: We simulated RCT data using diverse assumptions
  for the average treatment effect, a baseline prognostic index of risk
  (PI), the shape of its interaction with treatment (none, linear,
  quadratic or non-monotonic), and the magnitude of treatment-related
  harms (none or constant independent of the PI). We predicted absolute
  benefit using: models with a constant relative treatment effect;
  stratification in quarters of the PI; models including a linear
  interaction of treatment with the PI; models including an interaction
  of treatment with a restricted cubic spline (RCS) transformation of
  the PI; an adaptive approach using Akaike's Information Criterion. We
  evaluated predictive performance using root mean squared error and
  measures of discrimination and calibration for benefit.
  \textbf{Results}: The linear-interaction model and the RCS-interaction
  displayed robust performance across many simulation scenarios. The
  RCS-model was optimal when quadratic or non-monotonic deviations from
  a constant treatment effect were stronger, and when sample size was
  larger. The adaptive approach required larger sample sizes.
  Illustrations in the GUSTO-I trial confirmed these findings.
  \textbf{Conclusion}: An interaction between baseline risk and
  treatment assignment should be considered to improve treatment effect
  predictions.
  \end{abstract}
   \begin{keyword} treatment effect heterogeneity absolute
benefit prediction models\end{keyword}
 \end{frontmatter}

\doublespacing 
\linenumbers

\hypertarget{what-is-new}{%
\section*{What is new?}\label{what-is-new}}
\addcontentsline{toc}{section}{What is new?}

\begin{itemize}
\tightlist
\item
  Models including a linear interaction of the prognostic index with
  treatment were a good option for predicting absolute benefit with
  smaller sample sizes or moderately performing prediction models.
\item
  Models including an interaction of treatment with a restricted cubic
  spline transformation using 3 knots performed better in the presence
  of true non-monotonic deviations from a constant relative treatment
  effect or with treatment-related harms.
\item
  Using an AIC adaptive approach to select among a constant effects
  model, a linear interaction model, and a model using restricted cubic
  spline transformations was better suited for larger sample sizes.
\end{itemize}

\hypertarget{what-this-adds-to-what-was-known}{%
\section*{What this adds to what was
known?}\label{what-this-adds-to-what-was-known}}
\addcontentsline{toc}{section}{What this adds to what was known?}

\begin{itemize}
\tightlist
\item
  Using a constant relative treatment effect for making risk-based
  individualized benefit predictions is not always the best approach.
\item
  Models including linear interaction of treatment with the prognostic
  index have robust performance across a wide variety of settings.
\item
  Increasing the flexibility of the transformation of the prognostic
  index does not improve performance.
\end{itemize}

\hypertarget{what-is-the-implication-and-what-should-change-now}{%
\section*{What is the implication and what should change
now?}\label{what-is-the-implication-and-what-should-change-now}}
\addcontentsline{toc}{section}{What is the implication and what should
change now?}

\begin{itemize}
\tightlist
\item
  Assuming a constant relative treatment effect for all patients may
  lead to treatment mistargeting.
\item
  We recommend using a linear interaction of treatment with the
  prognostic index for making individualized risk-based benefit
  predictions.
\item
  With larger sample size, using an adaptive approach based on AIC to
  explore non-linear interactions of the prognostic index with treatment
  is a viable option.
\end{itemize}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Predictive approaches for assessing heterogeneity of treatment effects
(HTE) aim at the development of models predicting either individualized
effects or which of two (or more) treatments is better for an individual
{[}1{]}. In prior work, we divided such methods in three broader
categories based on the reference class used for defining patient
similarity when making individualized predictions or recommendations
{[}2{]}. First, risk-modeling approaches use prediction of baseline risk
as the reference; second, treatment effect modeling approaches also
model treatment-covariate interactions, in addition to risk factors;
third, optimal treatment regime approaches focus on developing treatment
assignment rules and rely heavily on modeling treatment effect
modifiers. A key difference between these approaches is their parsimony
in dealing the treatment effect modifiers, with no interaction
considered (risk modeling), a limited number of interactions (effect
modeling), or a larger set of interactions (optimal treatment regime
approaches).

Risk-modeling approaches to predictive HTE analyses provide a viable
option in the absence of well-established treatment effect modifiers
{[}3,4{]}. In simulations, modeling of effect modifiers, i.e.
treatment-covariate interactions, often led to miscalibrated predictions
of absolute benefit, while risk-based methods proved quite robust in
terms of benefit calibration, although provided weaker discrimination of
benefit in the presence of true effect modifiers {[}5{]}. Most often,
risk-modeling approaches are carried out in two steps: first a risk
prediction model is developed externally or internally on the entire RCT
population, ``blinded'' to treatment; then the RCT population is
stratified using this prediction model to evaluate risk-based treatment
effect variation {[}6{]}. This two-step approach identified substantial
absolute treatment effect differences between low-risk and high-risk
patients in a re-analysis of 32 large trials {[}7{]}. However, even
though estimates at the risk subgroup level may be accurate, these
estimates may need further refinement for individual patients,
especially for patients with predicted risk at the boundaries of the
risk intervals. Hence, the risk-stratified approach is useful for
exploring and presenting HTE, but is not sufficient for supporting
treatment decisions for individual patients.

To individualize treatment effects, the recent PATH statement suggested
various risk-based models including a prognostic index of baseline risk
(PI) and treatment assignment {[}3,4{]}. In the current simulation
study, we aim to summarize and compare different risk-based models for
predicting individualized treatment effects. We simulate different
relations between baseline risk and treatment effects and also consider
potential harms of treatment. We illustrate the different models by a
case study of predicting individualized effects of treatment for acute
myocardial infarction (MI) in a large randomized controlled trial (RCT).

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{background}{%
\subsection{Background}\label{background}}

We observe RCT data \((Z, X, Y)\), where for each patient \(Z_i= 0, 1\)
is the treatment status, \(Y_i = 0, 1\) is the observed outcome and
\(X_i\) is a set of covariates measured. Let \(\{Y_i(z), z=0, 1\}\)
denote the unobservable potential outcomes. We observe
\(Y_i = Z_iY_i(1) + (1 - Z_i)Y_i(0)\). We are interested in predicting
the conditional average treatment effect (CATE),
\[\tau(x) = E\{Y(0) - Y(1)|X=x\}\] Assuming that \((Z, X, Y)\) is a
random sample from the target population and that
\(\big(Y(0), Y(1)\big)\perp \!\!\! \perp Z|X\), as we are in the RCT
setting, we can predict CATE from \begin{align*}
\tau(x) &= E\{Y(0)\:\vert\:X=x\}-E\{Y(1)\:\vert\:X=x\}\\
&=E\{Y\:\vert\:X=x, Z=0\}-E\{Y\:\vert\:X=x, Z=1\}
\end{align*}

Based on an estimate of baseline risk \[
E\{Y\:\vert\:X=x, Z=0\}=g\big(lp(x)\big)
\] with \(u=lp(x)=\hat{\beta}^tx\) the linear predictor and \(g\) the
link function, we predict CATE from \[
\hat{\tau}(x) = g\big(f(u, 0)\big) - g\big(f(u, 1)\big)
\] where \(f(u,z)\) describes interactions of the baseline risk linear
predictor with treatment. In the rest of the paper we use the linear
predictor \(lp(x)\) as the prognostic index (PI) for the outcome \(Y\).

\hypertarget{simulation-scenarios}{%
\subsection{Simulation scenarios}\label{simulation-scenarios}}

We simulated a typical RCT that is undertaken to compare a binary
outcome (e.g.~death) between a group of patients in the treatment arm
and a group of untreated patients in the control arm. For each patient
we generated 8 baseline covariates \(x_1,\dots,x_4\sim N(0, 1)\) and
\(x_5,\dots,x_8\sim B(1, 0.2)\). Treatment was allocated using a 50:50
split. Outcomes for patients in the control arm were generated from a
logistic regression model including all baseline covariates. In the base
scenarios coefficient values were such, that the AUC of the logistic
regression model was \(0.75\) and the event rate in the control arm was
\(20\%\). Binary outcomes in the control arm were generated from
Bernoulli variables with true probabilities
\(P(y=1|X, t_x = 0) = \text{expit}(PI)=\frac{e^{PI}}{1+e^{PI}}\).

Outcomes in the treatment arm were generated using 3 base scenarios:
absent treatment effect (OR = 1), moderate treatment effect (OR = 0.8)
and strong treatment effect (OR = 0.5). We started with simulating
outcomes based on true constant relative treatment effects for the 3
base scenarios. We then simulated linear, quadratic and non-monotonic
deviations from constant treatment effects using:
\[lp_1 = \gamma_2(PI-c)^2 + \gamma_1(PI-c) + \gamma_0, \] where \(lp_1\)
is the true linear predictor in the treatment arm, so that
\(P(y=1|X, Z=1) = \text{expit}(lp_1)\). Finally, we simulated scenarios
where a constant absolute harm is applied across all treated patients.
In this case we have
\(P(y=1|X,Z=1) = \text{expit}(lp_1) + \text{harm}\).

The sample size for the base scenarios was set to 4,250, since this
sample size provides \(80\%\) power for the detection of a marginal OR
of 0.8 with the standard alpha of 0.5\%. We evaluated the effect of
smaller or larger sample sizes of 1,063 (4,250 divided by 4) and 17,000
(4250 multiplied by 4), respectively. We also evaluated the effect of
worse or better discriminative ability for risk, adjusting the baseline
covariate coefficients, such that the AUC of the regression model in the
control arm was 0.65 and 0.85 respectively.

Combining all these settings resulted in a simulation study of 648
scenarios (exact settings in the supplementary material). With these
scenarios we were able to cover the observed treatment effect
heterogeneity in 32 large trials as well as many other potential
variations of risk-based treatment effect {[}7{]}.

\hypertarget{individualized-risk-based-benefit-predictions}{%
\subsection{Individualized risk-based benefit
predictions}\label{individualized-risk-based-benefit-predictions}}

All risk-based methods assume that a risk prediction model is available
to assign risk predictions to individual patients. For the simulations
we developed a prediction model internally on the entire population,
using a logistic regression model with main effects for all baseline
covariates and treatment assignment. Baseline risk predictions for
individual patients were derived by setting treatment assignment to 0.
Another common approach is to derive the prediction model solely on the
control patients, however this approach has been shown to lead to biased
benefit predictions {[}5,8,9{]}.

A \emph{stratified HTE method} has been suggested as an alternative to
traditional subgroup analyses {[}3,4{]}. Patients are stratified into
equally-sized risk strata---in this case based on risk quartiles.
Absolute treatment effects within risk strata are estimated by the
difference in event rate between patients in the control arm and
patients in the treated arm. We considered this approach as a reference,
expecting it to perform worse than the other candidates, as its
objective is to provide an illustration of HTE rather than to optimize
individualized benefit predictions.

Second, we considered a model which assumes \emph{constant relative
treatment effect} (constant odds ratio). Hence, absolute benefit is
predicted from
\(\hat{\tau}(\bm{x}) = \text{expit}(PI) - \text{expit}(PI +\log(\text{OR}))\).

Third, we considered a logistic regression model including treatment,
the prognostic index, and their linear interaction. Absolute benefit is
then estimated from
\(\hat{\tau}(\bm{x})=\text{expit}(\beta_0+\beta_{PI}PI) - \text{expit}(\beta_0+\beta_{t_x}+(\beta_{PI}+\beta_*)PI)\).
We will refer to this method as the \emph{linear interaction} approach.

Fourth, we used \emph{restricted cubic splines} (RCS) to relax the
linearity assumption on the effect of the linear predictor {[}10{]}. We
considered splines with 3 (RCS-3), 4 (RCS-4) and 5 (RCS-5) knots to
compare models with different levels of flexibility.

Finally, we considered an \emph{adaptive approach} using Akaike's
Information Criterion (AIC) for model selection. More specifically, for
the adaptive approach we ranked the constant relative treatment effect
model, the linear interaction model, and the RCS models with 3, 4, and 5
knots based on their AIC and selected the one with the lowest value. The
extra degrees of freedom were 1 (linear interaction), 2, 3 and 4 (RCS
models) for these increasingly complex interactions with the treatment
effect.

\hypertarget{evaluation-metrics}{%
\subsection{Evaluation metrics}\label{evaluation-metrics}}

We evaluated the predictive accuracy of the considered methods by the
root mean squared error (RMSE):

\[\text{RMSE}=\sqrt{\frac{1}{n}\sum_{i=1}^n\big(\tau(\bm{x}_i) - \hat{\tau}(\bm{x}_i)\big)^2}\]
We compared the discriminative ability of the methods under study using
c-for-benefit {[}11{]}. The c-for-benefit represents the probability
that from two randomly chosen matched patient pairs with unequal
observed benefit, the pair with greater observed benefit also has a
higher predicted benefit. To be able to calculate observed benefit,
patients in each treatment arm are ranked based on their predicted
benefit and then matched 1:1 across treatment arms. \emph{Observed}
treatment benefit is defined as the difference of observed outcomes
between the untreated and the treated patient of each matched patient
pair. \emph{Predicted} benefit is defined as the average of predicted
benefit within each matched patient pair.

We evaluated calibration in a similar manner, using the integrated
calibration index (ICI) for benefit {[}12{]}. The observed benefits are
regressed on the predicted benefits using a locally weighted scatterplot
smoother (loess). The ICI-for-benefit is the average absolute difference
between predicted and smooth observed benefit. Values closer to \(0\)
represent better calibration.

For each scenario setting we performed 500 replications, within which
all the considered models were fitted. For comparing between models we
simulated a super-population of size 500,000 for each scenario. We
calculated RMSE and discrimination and calibration for benefit of the
models derived in each replication of our simulation settings within
this super-population.

\hypertarget{empirical-illustration}{%
\subsection{Empirical illustration}\label{empirical-illustration}}

We demonstrated the different methods for individualizing treatment
benefits using data from 30,510 patients with acute myocardial
infarction (MI) included in the GUSTO-I trial. 10,348 patients were
randomized to tissue plasminogen activator (tPA) treatment and 20,162
were randomized to streptokinase. The outcome of interest was 30-day
mortality (total of 2,128 events), recorded for all patients.

In line with previous analyses {[}13,14{]}, we fitted a logistic
regression model with 6 baseline covariates, i.e.~age, Killip class,
systolic blood pressure, heart rate, an indicator of previous MI, and
the location of MI, to predict 30-day mortality risk. A constant effect
of treatment was included in the model. When deriving risk predictions
for individuals we set the treatment indicator to 0. More information on
model development can be found in the supplement (Supplement, Section
8).

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{simulations}{%
\subsection{Simulations}\label{simulations}}

The linear interaction model outperformed all RCS methods in terms of
RMSE in scenarios with true constant relative treatment effect (OR =
0.8, N = 4,250 and AUC = 0.75), strong linear and even strong quadratic
deviations from a constant relative treatment effect (Figure
\ref{fig:rmsebase}; panels A-C). However, with non-monotonic deviations
from a constant relative treatment effect, the RMSE of the linear
interaction model increased substantially, especially in the presence of
treatment-related harms (Figure \ref{fig:rmsebase}; panel D). In these
scenarios, RCS-3 outperformed all other methods in terms of RMSE. As
might be expected the constant treatment effect approach had overall
best performance under true constant treatment effect settings. It was
sensitive to all considered deviations, resulting in increased RMSE.
Finally, the adaptive approach had comparable performance to the
best-performing method in each scenario. However, in comparison with the
best-performing approach, its RMSE was more variable in the scenarios
with linear and non-monotonic deviations, especially when also including
moderate or strong treatment-related harms. On closer inspection, we
found that this behavior was caused by wrongly selecting the constant
treatment effect model in a substantial proportion of the replications
(Supplement, Figure S3). This problematic behavior was less with larger
sample sizes (see below).

\begin{figure}
\includegraphics[width=1\linewidth]{manuscript_files/figure-latex/rmsebase-1} \caption{RMSE of the considered methods across 500 replications calculated from a simulated super-population of size 500,000. The scenario with true constant relative treatment effect (panel A) had a true prediction AUC of 0.75 and sample size of 4250. The RMSE is also presented for strong linear (panel B), strong quadratic (panel C), and non-monotonic (panel D) from constant relative treatment effects. Panels on the right side present the true relations between baseline risk (x-axis) and absolute treatment benefit (y-axis). The 2.5, 25, 50, 75, and 97.5 percentiles of the risk distribution are expressed by the boxplot on the top. The 2.5, 25, 50, 75, and 97.5 percentiles of the true benefit distributions are expressed by the boxplots on the side of the right-handside panel.}\label{fig:rmsebase}
\end{figure}

Increasing the sample size to 17,000 favored RCS-3 the most, It achieved
lowest or close to lowest RMSE across all scenarios (Figure
\ref{fig:rmsesamplesize}). Especially in cases of strong quadratic and
non-monotonic deviations RCS-3 had lower RMSE (median 0.011 for strong
quadratic deviations and 0.010 for non-monotonic deviations with no
treatment-related harms) compared to the linear interaction approach
(median 0.013 and 0.014, respectively), regardless of the strength of
treatment-related harms. Due to the large sample size, the RMSE of the
adaptive approach was even more similar to the best-performing method,
and the constant relative treatment effect model was less often wrongly
selected (Supplement, Figure S4).

\begin{figure}
\includegraphics[width=1\linewidth]{manuscript_files/figure-latex/rmsesamplesize-1} \caption{RMSE of the considered methods across 500 replications calculated in simulated samples of size 17,000 rather than 4,250 in Figure \ref{fig:rmsebase}. RMSE was calculated on a super-population of size 500,000}\label{fig:rmsesamplesize}
\end{figure}

When we increased the AUC of the true prediction model to 0.85 (OR = 0.8
and N = 4,250). RCS-3 had the lowest RMSE in the case of strong
quadratic or non-monotonic deviations and very comparable performance to
the -- optimal -- linear interaction model in the case of strong linear
deviations (median RMSE 0.016 for RCS-3 compared to 0.014 for the linear
interaction model). As observed in the base case scenario the adaptive
approach wrongly selected the constant treatment effect model (23\% and
25\% of the replications in the strong linear and non-monotonic
deviation scenarios without treatment-related harms, respectively),
leading to more variability of the RMSE (Supplement, Figure S5).

\begin{figure}
\includegraphics[width=1\linewidth]{manuscript_files/figure-latex/rmseauc-1} \caption{RMSE of the considered methods across 500 replications calculated in simulated samples 4,250. True prediction AUC of 0.85. RMSE was calculated on a super-population of size 500,000}\label{fig:rmseauc}
\end{figure}

When assuming a true constant relative treatment effect, discrimination
for benefit was only slightly lower for the linear interaction model,
but substantially lower for the non-linear RCS approaches (Figure
\ref{fig:discrimination}; panel A). With strong linear or quadratic
deviations from a constant relative treatment effect, all methods
discriminated quite similarly (Figure \ref{fig:discrimination}; panels
B-C). In the scenario with non-monotonic deviations, the constant effect
model had much lower discriminative ability compared to all other
methods (median AUC of 0.4971 for the constant effects model, 0.5285 for
the linear interaction model and 0.5304 for the best-performing RCS-3;
Figure \ref{fig:discrimination}; panel D). The adaptive approach was
unstable in terms of discrimination for benefit, especially in the
presence of treatment-related harms. With increasing number of RCS
knots, we observed decreasing median values and increasing variability
of the c-for-benefit in all scenarios. When we increased the sample size
to 17,000 we observed similar trends, however the performance of all
methods was more stable (Supplement, Figure S6). Finally, when we
increased the true prediction AUC to 0.85 the adaptive approach in the
case of non-monotonic deviations was, again, more conservative,
especially with null or moderate treatment-related harms (Supplement,
Figure S5).

\begin{figure}
\includegraphics[width=1\linewidth]{manuscript_files/figure-latex/discrimination-1} \caption{Discrimination for benefit of the considered methods across 500 replications calculated in a simulated samples of size 4,250. True prediction AUC of 0.75.}\label{fig:discrimination}
\end{figure}

In terms of calibration for benefit, the constant effects model
outperformed all other models in the scenario with true constant
treatment effects, but was miscalibrated for all deviation scenarios
(Figure \ref{fig:calibration}). The linear interaction model showed best
or close to best calibration across all scenarios and only showed worse
calibration compared to RCS-3 in case of non-monotonic deviations and
treatment-related harms (Figure \ref{fig:calibration}; panel D). The
adaptive approach was worse calibrated in scenarios with strong linear
and non-monotonic deviations compared to the linear interaction model
and RCS-3. When we increased sample size to 17,000 similar conclusions
on calibration for benefit could be drawn. As expected, all methods
displayed more stable calibration performance due to the larger number
of patients (Supplement, Figure S6). When we increased the true
prediction AUC to 0.85, the linear interaction model was worse
calibrated, on average, than RCS-3 in the case of strong quadratic
deviations from constant relative treatment effects (Supplement, Figure
S7).

The results from all individual scenarios can be explored online at
\url{https://arekkas.shinyapps.io/simulation_viewer/}. Additionally, all
the code for the simulations can be found at
\url{https://github.com/rekkasa/arekkas_HteSimulation_XXXX_2021}

\begin{figure}
\includegraphics[width=1\linewidth]{manuscript_files/figure-latex/calibration-1} \caption{Calibration for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. True prediction AUC of 0.75 and sample size of 4,250.}\label{fig:calibration}
\end{figure}

\hypertarget{empirical-illustration-1}{%
\subsection{Empirical illustration}\label{empirical-illustration-1}}

We used the derived prognostic index to fit a constant treatment effect
model, a linear interaction model and a RCS-3 model individualizing
absolute benefit predictions. RCS-4 and RCS-5 models were excluded. In
our simulations these methods were always outperformed by the simpler
approaches and were often overfitted. Finally, an adaptive approach with
only the 3 candidate models was also applied.

All considered methods provided similar fits, predicting increasing
benefits for patients with higher baseline risk predictions. All models
followed the evolution of the stratified estimates very closely. The
adaptive approach based on AIC selected the constant treatment effect
model. The constant treatment effect model had somewhat lower AIC
compared to the linear interaction model slightly worse cross-validated
discrimination (c-for-benefit 0.525 vs 0.526) and better cross-validated
calibration (ICI-for benefit 0.0104 vs 0.0115). In conclusion, a simpler
constant treatment effect model is adequate for predicting absolute
30-day mortality benefits of treatment with tPA in patients with with
acute MI.

\begin{figure}
\includegraphics[width=1\linewidth]{manuscript_files/figure-latex/gusto-1} \caption{Individualized absolute benefit predictions based on baseline risk when using a constant treatment effect approach, a linear interaction approach and RCS smoothing using 3 knots. Risk stratified estimates of absolute benefit are presented within quartiles of baseline risk as reference.}\label{fig:gusto}
\end{figure}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

The linear interaction model and the RCS-3 model both displayed very
good performance under many of the considered simulation scenarios. The
linear interaction model was optimal in cases with smaller sample sizes
and moderately performing baseline risk prediction models, that is, it
had lower RMSE, was better calibrated for benefit and had better
discrimination for benefit, even in scenarios with strong quadratic
deviations. In scenarios with true non-monotonic deviations, the linear
interaction model was outperformed by RCS-3, especially in the presence
of true treatment-related harms. Increasing the sample size or the
prediction model's discriminative ability favored RCS-3, especially in
scenarios with non-monotonic deviations and in the presence of
treatment-related harms.

RCS-4 and RCS-5 proved to be too flexible in all considered scenarios,
as indicated by higher RMSE, increased variability of discrimination for
benefit and worse calibration of benefit predictions. Even with larger
sample sizes and strong quadratic or non-monotonic deviations from the
base case scenario of constant relative treatment effects, these more
flexible restricted cubic splines did not outperform the simpler RCS-3.
These approaches may only be helpful if we expect more extreme patterns
of heterogeneous treatment effects compared to the quadratic deviations
considered here. Considering interactions in RCS-3 models as the most
complex approach often may be reasonable.

The constant treatment effect model, despite having adequate performance
in the presence of weak treatment effect heterogeneity on the relative
scale, quickly broke down with stronger deviations from constant
relative treatment effects. In these cases, the stratified approach
generally had lower error rates compared to the constant treatment
effect model. Such stepwise treatment benefit estimates are useful for
visually demonstrating treatment effect heterogeneity but may be
considered insufficient for making individualized benefit predictions.

Increasing the discriminative ability of the risk model--by increasing
the predictor coefficients of the true risk model--reduced RMSE for all
methods. This increase in discriminative ability translates in higher
variability of predicted risks, which, in turn, allows the considered
methods to better capture absolute treatment benefits. As a consequence,
the increase in discriminative ability of the risk model also led to
higher discrimination between those with low or high benefit (as
reflected in values of c-for-benefit). Even though risk model
performance is very important for the ability of risk-based methods to
predict treatment benefit, prediction model development was outside the
scope of this work and has already been studied extensively {[}5,8,9{]}.

The adaptive approach had adequate performance, following closely on
average the performance of the ``true'' model in most scenarios. With
smaller sample sizes it tended to miss the treatment-risk interactions
and selected simpler models (Supplement Section 4). This conservative
behavior resulted in increased RMSE variability in these scenarios,
especially in the case of true strong linear or non-monotonic deviations
from the base case scenario. Therefore, in the case of smaller sample
sizes the simpler linear interaction model may be a safer choice for
predicting absolute benefits in the presence of any suspected
treatment-related harms.

A limitation of our study is that we assumed treatment benefit to be a
function of baseline risk in the majority of the simulation scenarios.
We also considered constant moderate and strong treatment-related harms,
applied on the absolute scale to expand the range of scenarios in line
with previous work {[}15{]}. In a limited set of scenarios where we
assumed the existence of true treatment-covariate interactions, our
conclusions remained unchanged. Even though the average error rates
increased for all the considered methods, due to the miss-specification
of the outcome model, the linear interaction model had the lowest error
rates. RCS-3 had very comparable performance. The constant treatment
effect model often gave biased results, espcially in the presence of
moderate or strong treatment-related harms. All the results of these
simulations can be found in Supplement, Section 7. Future simulation
studies could explore the effect of more extensive deviations from
risk-based treatment effects.

In our simulations we only focused on risk-based methods, using baseline
risk as a reference in a two-stage approach to individualizing benefit
predictions. However, there is a plethora of different methods, ranging
from treatment effect modeling to tree-based approaches available in
more recent literature {[}16--19{]}. Many of these methods rely on
incorporating treatment-covariate interactions in the prediction of
benefit. An important caveat of such approaches is that they may be
prone to overfitting, thus exaggerating the magnitude of the predicted
benefits. In a wide range of simulation settings, a simpler risk
modeling approach was consistently better calibrated for benefit
compared to more complex treatment effect modelling approaches {[}5{]}.
However, whether this remains the case in a range of empirical settings
still needs to be explored Similarly, when SYNTAX score II, a model
developed for identifying patients with complex coronary artery disease
that benefit more from percutaneous coronary intervention or from
coronary artery bypass grafting was redeveloped using fewer
treatment-covariate interactions had better external performance
compared to its predecessor{[}20,21{]}.

In conclusion, the linear interaction approach is a viable option with
smaller sample sizes and/or moderately performing risk prediction models
if we consider a non-constant relative treatment effect plausible. RCS-3
is a better option when non-monotonic deviations from a constant
relative treatment effect and/or substantial treatment-related harms are
anticipated. Increasing the complexity of the RCS models by increasing
the number of knots does not translate to improved benefit prediction.
Using AIC for model selection among the constant treatment effect, the
linear interaction and RCS-3 model is a viable option, especially with
larger sample size.

\newpage

\hypertarget{references}{%
\section{References}\label{references}}

\setlength{\parindent}{-0.25in}
\setlength{\leftskip}{0.25in}

\noindent

\hypertarget{refs}{}
\begin{cslreferences}
\leavevmode\hypertarget{ref-Varadhan2013}{}%
{[}1{]} Varadhan R, Segal JB, Boyd CM, Wu AW, Weiss CO. A framework for
the analysis of heterogeneity of treatment effect in~patient-centered
outcomes research. Journal of Clinical Epidemiology 2013;66:818--25.
\url{https://doi.org/10.1016/j.jclinepi.2013.02.009}.

\leavevmode\hypertarget{ref-Rekkas2020}{}%
{[}2{]} Rekkas A, Paulus JK, Raman G, Wong JB, Steyerberg EW, Rijnbeek
PR, et al. Predictive approaches to heterogeneous treatment effects: A
scoping review. BMC Medical Research Methodology 2020;20.
\url{https://doi.org/10.1186/s12874-020-01145-1}.

\leavevmode\hypertarget{ref-Kent2019}{}%
{[}3{]} Kent DM, Paulus JK, Klaveren D van, D'Agostino R, Goodman S,
Hayward R, et al. The predictive approaches to treatment effect
heterogeneity (PATH) statement. Annals of Internal Medicine 2019;172:35.
\url{https://doi.org/10.7326/m18-3667}.

\leavevmode\hypertarget{ref-PathEnE}{}%
{[}4{]} Kent DM, Klaveren D van, Paulus JK, D'Agostino R, Goodman S,
Hayward R, et al. The predictive approaches to treatment effect
heterogeneity (PATH) statement: Explanation and elaboration. Annals of
Internal Medicine 2019;172:W1. \url{https://doi.org/10.7326/m18-3668}.

\leavevmode\hypertarget{ref-vanKlaveren2019}{}%
{[}5{]} Klaveren D van, Balan TA, Steyerberg EW, Kent DM. Models with
interactions overestimated heterogeneity of treatment effects and were
prone to treatment mistargeting. Journal of Clinical Epidemiology
2019;114:72--83. \url{https://doi.org/10.1016/j.jclinepi.2019.05.029}.

\leavevmode\hypertarget{ref-Kent2010}{}%
{[}6{]} Kent DM, Rothwell PM, Ioannidis JP, Altman DG, Hayward RA.
Assessing and reporting heterogeneity in treatment effects in clinical
trials: A proposal. Trials 2010;11.
\url{https://doi.org/10.1186/1745-6215-11-85}.

\leavevmode\hypertarget{ref-Kent2016}{}%
{[}7{]} Kent DM, Nelson J, Dahabreh IJ, Rothwell PM, Altman DG, Hayward
RA. Risk and treatment effect heterogeneity: Re-analysis of individual
participant data from 32 large clinical trials. International Journal of
Epidemiology 2016:dyw118. \url{https://doi.org/10.1093/ije/dyw118}.

\leavevmode\hypertarget{ref-Burke2014}{}%
{[}8{]} Burke JF, Hayward RA, Nelson JP, Kent DM. Using internally
developed risk models to assess heterogeneity in treatment effects in
clinical trials. Circulation: Cardiovascular Quality and Outcomes
2014;7:163--9. \url{https://doi.org/10.1161/circoutcomes.113.000497}.

\leavevmode\hypertarget{ref-Abadie2018}{}%
{[}9{]} Abadie A, Chingos MM, West MR. Endogenous stratification in
randomized experiments. The Review of Economics and Statistics
2018;100:567--80. \url{https://doi.org/10.1162/rest_a_00732}.

\leavevmode\hypertarget{ref-Harrell1988}{}%
{[}10{]} Harrell FE, Lee KL, Pollock BG. Regression models in clinical
studies: Determining relationships between predictors and response. JNCI
Journal of the National Cancer Institute 1988;80:1198--202.
\url{https://doi.org/10.1093/jnci/80.15.1198}.

\leavevmode\hypertarget{ref-vanKlaveren2018}{}%
{[}11{]} Klaveren D van, Steyerberg EW, Serruys PW, Kent DM. The
proposed ``concordance-statistic for benefit'' provided a useful metric
when modeling heterogeneous treatment effects. Journal of Clinical
Epidemiology 2018;94:59--68.
\url{https://doi.org/10.1016/j.jclinepi.2017.10.021}.

\leavevmode\hypertarget{ref-Austin2019}{}%
{[}12{]} Austin PC, Steyerberg EW. The integrated calibration index
(ICI) and related metrics for quantifying the calibration of logistic
regression models. Statistics in Medicine 2019;38:4051--65.
\url{https://doi.org/10.1002/sim.8281}.

\leavevmode\hypertarget{ref-Califf1997}{}%
{[}13{]} Califf RM, Woodlief LH, Harrell FE, Lee KL, White HD, Guerci A,
et al. Selection of thrombolytic therapy for individual patients:
Development of a clinical model. American Heart Journal 1997;133:630--9.
\url{https://doi.org/10.1016/s0002-8703(97)70164-9}.

\leavevmode\hypertarget{ref-Steyerberg2000}{}%
{[}14{]} Steyerberg EW, Bossuyt PMM, Lee KL. Clinical trials in acute
myocardial infarction: Should we adjust for baseline characteristics?
American Heart Journal 2000;139:745--51.
\url{https://doi.org/10.1016/s0002-8703(00)90001-2}.

\leavevmode\hypertarget{ref-Glasziou1995}{}%
{[}15{]} Glasziou PP, Irwig LM. An evidence based approach to
individualising treatment. BMJ 1995;311:1356--9.
\url{https://doi.org/10.1136/bmj.311.7016.1356}.

\leavevmode\hypertarget{ref-Athey2019}{}%
{[}16{]} Athey S, Tibshirani J, Wager S. Generalized random forests. The
Annals of Statistics 2019;47. \url{https://doi.org/10.1214/18-aos1709}.

\leavevmode\hypertarget{ref-Lu2018}{}%
{[}17{]} Lu M, Sadiq S, Feaster DJ, Ishwaran H. Estimating individual
treatment effect in observational data using random forest methods.
Journal of Computational and Graphical Statistics 2018;27:209--19.
\url{https://doi.org/10.1080/10618600.2017.1356325}.

\leavevmode\hypertarget{ref-Wager2018}{}%
{[}18{]} Wager S, Athey S. Estimation and inference of heterogeneous
treatment effects using random forests. Journal of the American
Statistical Association 2018;113:1228--42.
\url{https://doi.org/10.1080/01621459.2017.1319839}.

\leavevmode\hypertarget{ref-powers2018some}{}%
{[}19{]} Powers S, Qian J, Jung K, Schuler A, Shah NH, Hastie T, et al.
Some methods for heterogeneous treatment effect estimation in high
dimensions. Statistics in Medicine 2018;37:1767--87.

\leavevmode\hypertarget{ref-farooq2013anatomical}{}%
{[}20{]} Farooq V, Van Klaveren D, Steyerberg EW, Meliga E, Vergouwe Y,
Chieffo A, et al. Anatomical and clinical characteristics to guide
decision making between coronary artery bypass surgery and percutaneous
coronary intervention for individual patients: Development and
validation of syntax score ii. The Lancet 2013;381:639--50.

\leavevmode\hypertarget{ref-takahashi2020redevelopment}{}%
{[}21{]} Takahashi K, Serruys PW, Fuster V, Farkouh ME, Spertus JA,
Cohen DJ, et al. Redevelopment and validation of the syntax score ii to
individualise decision making between percutaneous and surgical
revascularisation in patients with complex coronary artery disease:
Secondary analysis of the multicentre randomised controlled syntaxes
trial with external cohort validation. The Lancet 2020;396:1399--412.
\end{cslreferences}

\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}

\noindent


\end{document}
