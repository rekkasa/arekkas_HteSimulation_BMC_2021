---
title: |
 Individualized treatment effect was predicted best by modeling 
 baseline risk in interaction with treatment assignment
abstract: |
 **Objective**: To compare different risk-based methods for optimal prediction
 of individualized treatment effects. **Study Design and Setting**: We simulated
 RCT data using diverse assumptions for the average treatment effect, a baseline
 prognostic index of risk (PI), the shape of its interaction with treatment
 (none, linear, quadratic or non-monotonic), and the magnitude of
 treatment-related harms (none or constant independent of the PI). We predicted
 absolute benefit using: models with a constant relative treatment effect;
 stratification in quarters of the PI; models including a linear interaction of
 treatment with the PI; models including an interaction of treatment with a
 restricted cubic spline (RCS) transformation of the PI; an adaptive approach
 using Akaike’s Information Criterion. We evaluated predictive performance using
 root mean squared error and measures of discrimination and calibration for
 benefit. **Results**: The linear-interaction model and the RCS-interaction
 displayed robust performance across many simulation scenarios. The RCS-model
 was optimal when quadratic or non-monotonic deviations from a constant
 treatment effect were stronger, and when sample size was larger. The adaptive
 approach required larger sample sizes. Illustrations in the GUSTO-I trial
 confirmed these findings. **Conclusion**: An interaction between baseline risk
 and treatment assignment should be considered to improve treatment effect
 predictions.
author:
  - name: Alexandros Rekkas
    affiliation: 1
  - name: Peter R. Rijnbeek
    affiliation: 1
  - name: David M. Kent
    affiliation: 2
  - name: Ewout W. Steyerberg
    affiliation: 3
  - name: David van Klaveren
    affiliation: 4
address:
  - code: 1
    address: Department of Medical Informatics, Erasmus Medical Center, Rotterdam, The Netherlands
  - code: 2
    address: Predictive Analytics and Comparative Effectiveness Center, Institute for Clinical Research and Health Policy Studies, Tufts Medical Center, Boston, Massachusetts, USA
  - code: 3
    address: Department of Biomedical Data Sciences, Leiden University Medical Center, Leiden, The Netherlands
  - code: 4
    address: Department of Public Health, Erasmus Medical Center, Rotterdam, The Netherlands
numbersections: true
linenumbers: false
journal: arXiv.org
keywords:
  - treatment effect heterogeneity
  - absolute benefit
  - prediction models
output: 
  rticles::elsevier_article:
    keep_tex: true
  bookdown::word_document2:
    reference_docx: reference.docx
geometry: margin=1.0in
date: false
toc: false
font-size: 11pt
header-includes:
  - \renewcommand*\familydefault{\sfdefault}
  - \usepackage{setspace}
  - \usepackage{amsmath}
  - \doublespacing
  - \usepackage{amssymb}
  - \usepackage{bm}
  - \usepackage{caption}
  - \usepackage{booktabs}
  - \date{}
  - \newcommand\given[1][]{\:#1\vert\:}
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: jce.csl
---


```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(SmoothHte)
library(rms)
library(here)

d <- function(x, decimals = 4) {
  sprintf(paste0("%1.", decimals, "f"), x) 
}

knit_hooks$set(
  inline = function(x) {
    prettyNum(
      x,
      big.mark = ",",
      decimal.mark = ".",
      preserve.width = "individual"
    )
  }
  )
set.seed(19910930)
```

\doublespacing 
\linenumbers


# Introduction
Predictive approaches for assessing heterogeneity of treatment effects (HTE) aim
at the development of models predicting either individualized effects or which
of two (or more) treatments is better for an individual [@Varadhan2013]. In
prior work, we divided such methods in three broader categories based on the
reference class used for defining patient similarity when making individualized
predictions or recommendations [@Rekkas2020]. First, risk-modeling approaches
use prediction of baseline risk as the reference; second, treatment effect
modeling approaches also model treatment-covariate interactions, in addition to
risk factors; third, optimal treatment regime approaches focus on developing
treatment assignment rules and rely heavily on modeling treatment effect
modifiers. A key difference between these approaches is their parsimony in
dealing the treatment effect modifiers, with no interaction considered (risk
modeling), a limited number of interactions (effect modeling), or a larger set
of interactions (optimal treatment regime approaches).

Risk-modeling approaches to predictive HTE analyses provide a viable option in
the absence of well-established treatment effect modifiers [@Kent2019;
@PathEnE]. In simulations, modeling of effect modifiers, i.e.
treatment-covariate interactions, often led to miscalibrated predictions of
absolute benefit, while risk-based methods proved quite robust in terms of
benefit calibration, although provided weaker discrimination of benefit in the
presence of true effect modifiers [@vanKlaveren2019]. Most often, risk-modeling
approaches are carried out in two steps: first a risk prediction model is
developed externally or internally on the entire RCT population, “blinded” to
treatment; then the RCT population is stratified using this prediction model to
evaluate risk-based treatment effect variation [@Kent2010]. This two-step
approach identified substantial absolute treatment effect differences between
low-risk and high-risk patients in a re-analysis of 32 large trials
[@Kent2016]. However, even though estimates at the risk subgroup level may be
accurate, these estimates may need further refinement for individual patients,
especially for patients with predicted risk at the boundaries of the risk
intervals. Hence, the risk-stratified approach is useful for exploring and
presenting HTE, but is not sufficient for supporting treatment decisions for
individual patients.

To individualize treatment effects, the recent PATH statement suggested various
risk-based models including a prognostic index of baseline risk (PI) and
treatment assignment [@Kent2019; @PathEnE]. In the current simulation study, we aim to summarize and compare
different risk-based models for predicting individualized treatment effects. We
simulate different relations between baseline risk and treatment effects and also consider potential harms of treatment. We
illustrate the different models by a case study of predicting individualized
effects of treatment for acute myocardial infarction (MI) in a large randomized
controlled trial (RCT).

# Methods

## Simulation scenarios

We simulated a typical RCT that is undertaken to compare a binary outcome
(e.g. death) between a group of patients in the treatment arm and a
group of untreated patients in the control arm. For each patient we generated 8
baseline covariates $x_1,\dots,x_4\sim N(0, 1)$ and $x_5,\dots,x_8\sim B(1,
0.2)$. Treatment was allocated using a 50:50 split. Outcomes for patients in the
control arm were generated from a logistic regression model including all
baseline covariates. In the base scenarios coefficient values were such, that
the AUC of the logistic regression model was $0.75$ and the event rate in the
control arm was $20\%$. Binary outcomes in the control arm were generated from
Bernoulli variables with true probabilities
$P(y=1|X, t_x = 0) = \text{expit}(PI)=\frac{e^{PI}}{1+e^{PI}}$.

Outcomes in the treatment arm were generated using 3 base scenarios: absent
treatment effect (OR = 1), moderate treatment effect (OR = 0.8) and strong
treatment effect (OR = 0.5). We started with simulating outcomes based on true
constant relative treatment effects for the 3 base scenarios. We then simulated
linear, quadratic and non-monotonic deviations from constant treatment effects
using:
$$lp_1 = \gamma_2(PI-c)^2 + \gamma_1(PI-c) + \gamma_0, $$
where $lp_1$ is the true linear predictor in the treatment arm, so that
$P(y=1|X, t_x=1) = \text{expit}(lp_1)$. Finally, we simulated scenarios where a
constant absolute harm is applied across all treated patients. In this case we
have $P(y=1|X,t_x=1) = \text{expit}(lp_1) + \text{harm}$.

The sample size for the base scenarios was set to 4,250, since this sample size
provides $80\%$ power for the detection of a marginal OR of 0.8 with the
standard alpha of 0.5\%. We evaluated the effect of smaller or larger sample
sizes of 1,063 (4,250 divided by 4) and 17,000 (4250 multiplied by 4),
respectively. We also evaluated the effect of worse or better discriminative
ability for risk, adjusting the baseline covariate coefficients, such that the
AUC of the regression model in the control arm was 0.65 and 0.85 respectively.

Combining all these settings resulted in a simulation study of 648 scenarios
(exact settings in the supplementary material). With these scenarios we were
able to cover the observed treatment effect heterogeneity in 32 large trials as
well as many other potential variations of risk-based treatment effect
[@Kent2016].

## Individualized risk-based benefit predictions

All risk-based methods assume that a risk prediction model is available to
assign risk predictions to individual patients. For the simulations we developed
a prediction model internally on the entire population, using a logistic
regression model with main effects for all baseline covariates and treatment
assignment. Baseline risk predictions for individual patients were derived by
setting treatment assignment to 0. Another common approach is to derive the
prediction model solely on the control patients, however this approach has been
shown to lead to biased benefit predictions [@vanKlaveren2019; @Burke2014;
@Abadie2018].

A *stratified HTE method* has been suggested as an alternative to traditional
subgroup analyses [@Kent2019; @PathEnE]. Patients are stratified into
equally-sized risk strata---in this case based on risk quartiles. Absolute
treatment effects within risk strata are estimated by the difference in event
rate between patients in the control arm and patients in the treated arm. We
considered this approach as a reference, expecting it to perform worse than the
other candidates, as its objective is to provide an illustration of HTE rather
than to optimize individualized benefit predictions.

Second, we considered a model which assumes *constant relative treatment effect*
(constant odds ratio). Hence, absolute benefit is predicted from
$\hat{\tau}(\bm{x}) = \text{expit}(PI +\log(\text{OR}))$.

Third, we considered a logistic regression model including treatment, the
prognostic index, and their linear interaction. Absolute benefit is then
estimated from
$\hat{\tau}(\bm{x})=\text{expit}(\beta_0+\beta_{PI}PI) - \text{expit}(\beta_0+\beta_{t_x}+(\beta_{PI}+\beta_*)PI)$.
We will refer to this method as the *linear interaction* approach.

Fourth, we used *restricted cubic splines* (RCS) to relax the linearity
assumption on the effect of the linear predictor [@Harrell1988]. We considered
splines with 3 (RCS-3), 4 (RCS-4) and 5 (RCS-5) knots to compare models with
different levels of flexibility.

Finally, we considered an *adaptive approach* using Akaike's Information
Criterion (AIC) for model selection. More specifically, for the adaptive
approach we ranked the constant relative treatment effect model, the linear
interaction model, and the RCS models with 3, 4, and 5 knots based on their AIC
and selected the one with the lowest value. The extra degrees of freedom were 1
(linear interaction), 2, 3 and 4 (RCS models) for these increasingly complex
interactions with the treatment effect.

## Evaluation metrics
We evaluated the predictive accuracy of the considered methods by the root mean
squared error (RMSE):

$$\text{RMSE}=\sqrt{\frac{1}{n}\sum_{i=1}^n\big(\tau(\bm{x}_i) - \hat{\tau}(\bm{x}_i)\big)^2}$$
We compared the discriminative ability of the methods under study using
c-for-benefit [@vanKlaveren2018]. The c-for-benefit represents the probability
that from two randomly chosen matched patient pairs with unequal observed
benefit, the pair with greater observed benefit also has a higher predicted
benefit. To be able to calculate observed benefit, patients in each treatment
arm are ranked based on their predicted benefit and then matched 1:1 across
treatment arms. *Observed* treatment benefit is defined as the difference of
observed outcomes between the untreated and the treated patient of each matched
patient pair. *Predicted* benefit is defined as the average of predicted benefit
within each matched patient pair.

We evaluated calibration in a similar manner, using the integrated calibration
index (ICI) for benefit [@Austin2019]. The observed benefits are regressed on
the predicted benefits using a locally weighted scatterplot smoother (loess).
The ICI-for-benefit is the average absolute difference between predicted and
smooth observed benefit. Values closer to $0$ represent better calibration.

For each scenario setting we performed 500 replications, within which all the
considered models were fitted. For comparing between models we simulated a
super-population of size 500,000 for each scenario. We calculated RMSE and
discrimination and calibration for benefit of the models derived in each
replication of our simulation settings within this super-population. 

## Empirical illustration

```{r, echo=FALSE, warning=FALSE, message=FALSE}
load(here::here("data/raw/gusto.rda"))
gusto <- gusto %>%
  tibble() %>%
  filter(!is.na(tpa))

gusto <- gusto %>%
  tibble() %>%
  filter(tx != "SK+tPA") %>%
  rename(
    "outcome" = "day30",
    "treatment" = "tpa"
  )

treatmentArms <- gusto %>%
  group_by(treatment) %>%
  summarise(n = n())
```

We demonstrated the different methods for individualizing treatment benefits
using data from `r nrow(gusto)` patients with acute myocardial infarction (MI)
included in the GUSTO-I trial.
`r treatmentArms %>% filter(treatment == 1) %>% select(n)` 
patients were randomized to tissue plasminogen activator (tPA) treatment and
`r treatmentArms %>% filter(treatment == 0) %>% select(n)`
were randomized to streptokinase. The outcome of interest was 30-day mortality
(total of `r sum(gusto$outcome)` events), recorded for all patients.

In line with previous analyses [@Califf1997; @Steyerberg2000], we fitted a
logistic regression model with 6 baseline covariates, i.e. age, Killip class,
systolic blood pressure, heart rate, an indicator of previous MI, and the
location of MI, to predict 30-day mortality risk. A constant effect of treatment
was included in the model. When deriving risk predictions for individuals we set
the treatment indicator to 0. More information on model development can be found
in the supplement (Supplement, Section 8).

# Results

## Simulations

```{r adaptive, echo=FALSE, warning=FALSE, message=FALSE}
adaptiveSelections <- readr::read_csv(here::here("data/processed/adaptiveSelections.csv"))
rmseDistribution <- readr::read_csv(here::here("data/processed/rmseDistribution.csv"))
aucDistribution <- readr::read_csv(here::here("data/processed/discriminationDistribution.csv"))
```

The linear interaction model outperformed all RCS methods in terms of RMSE in
scenarios with true constant relative treatment effect (OR = 0.8, N = `r 4250`
and AUC = 0.75), strong linear and even strong quadratic deviations from a
constant relative treatment effect (Figure \ref{fig:rmsebase}; panels
A-C). However, with non-monotonic deviations from a constant relative treatment
effect, the RMSE of the linear interaction model increased substantially,
especially in the presence of treatment-related harms (Figure
\ref{fig:rmsebase}; panel D). In these scenarios, RCS-3 outperformed all other
methods in terms of RMSE. As might be expected the constant treatment effect
approach had overall best performance under true constant treatment effect
settings. It was sensitive to all considered deviations, resulting in increased
RMSE. Finally, the adaptive approach had comparable performance to the
best-performing method in each scenario. However, in comparison with the
best-performing approach, its RMSE was more variable in the scenarios with
linear and non-monotonic deviations, especially when also including moderate or
strong treatment-related harms. On closer inspection, we found that this
behavior was caused by wrongly selecting the constant
treatment effect model in a substantial proportion of the replications
(Supplement, Figure S3). This problematic behavior was less with larger sample
sizes (see below).

```{r rmsebase, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated from a simulated super-population of size 500,000. The scenario with true constant relative treatment effect (panel A) had a true prediction AUC of 0.75 and sample size of 4250. The RMSE is also presented for strong linear (panel B), strong quadratic (panel C), and non-monotonic (panel D) from constant relative treatment effects. Panels on the right side present the true relations between baseline risk (x-axis) and absolute treatment benefit (y-axis). The 2.5, 25, 50, 75, and 97.5 percentiles of the risk distribution are expressed by the boxplot on the top. The 2.5, 25, 50, 75, and 97.5 percentiles of the true benefit distributions are expressed by the boxplots on the side of the right-handside panel.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_moderate_base.tiff")))
# knitr::include_graphics(here::here("figures/rmse_base.png"))
```

Increasing the sample size to `r 17000` favored RCS-3 the most, It achieved
lowest or close to lowest RMSE across all scenarios (Figure
\ref{fig:rmsesamplesize}). Especially in cases of strong quadratic and
non-monotonic deviations RCS-3 had lower RMSE (median
`r rmseDistribution %>% filter(scenarioId == 385) %>% mutate(across(-one_of("scenarioId"), ~ d(.x, decimals = 3))) %>% pull(median_rcs_3)`
for strong quadratic deviations and 
`r rmseDistribution %>% filter(scenarioId == 421) %>% mutate(across(-one_of("scenarioId"), ~ d(.x, decimals = 3))) %>% pull(median_rcs_3)`
for non-monotonic deviations with no treatment-related harms) compared
to the linear interaction approach (median 
`r rmseDistribution %>% filter(scenarioId == 385) %>% mutate(across(-one_of("scenarioId"), ~ d(.x, decimals = 3))) %>% pull(median_linear)` and 
`r rmseDistribution %>% filter(scenarioId == 421) %>% mutate(across(-one_of("scenarioId"), ~ d(.x, decimals = 3))) %>% pull(median_linear)`,
respectively), regardless of the strength of treatment-related
harms. Due to the large sample size, the RMSE of the adaptive approach
was even more similar to the best-performing method, and the constant
relative treatment effect model was less often wrongly selected
(Supplement, Figure S4).

    
```{r rmsesamplesize, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in simulated samples of size 17,000 rather than 4,250 in Figure \\ref{fig:rmsebase}. RMSE was calculated on a super-population of size 500,000", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_moderate_sample_size.tiff")))
# knitr::include_graphics(here::here("figures/rmse_sample_size.png"))
```

When we increased the AUC of the true prediction model to 0.85 (OR = 0.8 and N =
`r 4250`). RCS-3 had the lowest RMSE in the case of strong quadratic or
non-monotonic deviations and very comparable performance to the -- optimal --
linear interaction model in the case of strong linear deviations (median RMSE
`r rmseDistribution %>% filter(scenarioId == 297) %>% mutate(across(-one_of("scenarioId"), ~ d(.x, decimals = 3))) %>% pull(median_rcs_3)` for RCS-3 compared to 
`r rmseDistribution %>% filter(scenarioId == 297) %>% mutate(across(-one_of("scenarioId"), ~ d(.x, decimals = 3))) %>% pull(median_linear)`
for the linear interaction model). As observed in the base case scenario the
adaptive approach wrongly selected the constant treatment effect model
(`r adaptiveSelections %>% filter(scenarioId == 297) %>% pull(treatment) * 100`\%
and
`r adaptiveSelections %>% filter(scenarioId == 405) %>% pull(treatment) * 100`\%
of the replications in the strong linear and non-monotonic deviation scenarios
without treatment-related harms, respectively), leading to more variability of
the RMSE (Supplement, Figure S5).

```{r rmseauc, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in simulated samples 4,250. True prediction AUC of 0.85. RMSE was calculated on a super-population of size 500,000", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_moderate_auc.tiff")))
# knitr::include_graphics(here::here("figures/rmse_auc.png"))
```

When assuming a true constant relative treatment effect, discrimination for
benefit was only slightly lower for the linear interaction model, but
substantially lower for the non-linear RCS approaches (Figure
\ref{fig:discrimination}; panel A). With strong linear or quadratic deviations
from a constant relative treatment effect, all methods discriminated quite
similarly (Figure \ref{fig:discrimination}; panels B-C). In the scenario with
non-monotonic deviations, the constant effect model had much lower
discriminative ability compared to all other methods (median AUC of
`r aucDistribution %>% filter(scenarioId == 397) %>% mutate(across(-one_of("scenarioId"), ~ d(.x))) %>% pull(median_constant)` 
for the constant effects model,
`r aucDistribution %>% filter(scenarioId == 397) %>% mutate(across(-one_of("scenarioId"), ~ d(.x))) %>% pull(median_linear)`
for the linear interaction model and
`r aucDistribution %>% filter(scenarioId == 397) %>% mutate(across(-one_of("scenarioId"), ~ d(.x))) %>% pull(median_rcs_3)`
for the best-performing RCS-3; Figure \ref{fig:discrimination}; panel D). The
adaptive approach was unstable in terms of discrimination for benefit,
especially in the presence of treatment-related harms. With increasing number of
RCS knots, we observed decreasing median values and increasing variability of
the c-for-benefit in all scenarios. When we increased the sample size to 17,000
we observed similar trends, however the performance of all methods was more
stable (Supplement, Figure S6). Finally, when we increased the true prediction
AUC to 0.85 the adaptive approach in the case of non-monotonic deviations was,
again, more conservative, especially with null or moderate treatment-related
harms (Supplement, Figure S5). 

```{r discrimination, cache=TRUE, echo=FALSE, fig.cap="Discrimination for benefit of the considered methods across 500 replications calculated in a simulated samples of size 4,250. True prediction AUC of 0.75.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/discrimination_moderate_base.tiff")))
# knitr::include_graphics(here::here("figures/discrimination_base.png"))
```

In terms of calibration for benefit, the constant effects model outperformed all
other models in the scenario with true constant treatment effects, but was
miscalibrated for all deviation scenarios (Figure \ref{fig:calibration}). The
linear interaction model showed best or close to best calibration across all
scenarios and only showed worse calibration compared to RCS-3 in case of
non-monotonic deviations and treatment-related harms (Figure
\ref{fig:calibration}; panel D). The adaptive approach was worse calibrated in
scenarios with strong linear and non-monotonic deviations compared to the linear
interaction model and RCS-3. When we increased sample size to 17,000 similar
conclusions on calibration for benefit could be drawn. As expected, all methods
displayed more stable calibration performance due to the larger number of
patients (Supplement, Figure S6). When we increased the true prediction AUC to
0.85, the linear interaction model was worse calibrated, on average, than RCS-3
in the case of strong quadratic deviations from constant relative treatment
effects (Supplement, Figure S7).

The results from all individual scenarios can be explored online at
[https://arekkas.shinyapps.io/simulation_viewer/](https://arekkas.shinyapps.io/simulation_viewer/). Additionally,
all the code for the simulations can be found at
[https://github.com/rekkasa/arekkas_HteSimulation_XXXX_2021](https://github.com/rekkasa/arekkas_HteSimulation_XXXX_2021)

```{r calibration, cache=TRUE, echo=FALSE, fig.cap="Calibration for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. True prediction AUC of 0.75 and sample size of 4,250.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/calibration_moderate_base.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```

## Empirical illustration


```{r, echo=FALSE, warning=FALSE, message=FALSE}
gustoPerformance <- readr::read_csv(here::here("data/processed/gustoPerformanceMetrics.csv"))

discriminationPerformance <- gustoPerformance %>%
  select("discrimination")
calibrationPerformance <- gustoPerformance %>%
  select("calibration")
```

We used the derived prognostic index to fit a constant treatment effect model, a
linear interaction model and a RCS-3 model individualizing absolute benefit
predictions. RCS-4 and RCS-5 models were excluded. In our simulations these
methods were always outperformed by the simpler approaches and were often
overfitted. Finally, an adaptive approach with only the 3 candidate models was
also applied.

All considered methods provided similar fits, predicting increasing benefits for
patients with higher baseline risk predictions. All models followed the
evolution of the stratified estimates very closely. The adaptive approach based
on AIC selected the constant treatment effect model. The constant treatment
effect model had somewhat lower AIC compared to the linear interaction model
slightly worse cross-validated discrimination (c-for-benefit
`r round(discriminationPerformance[1, ], 3)` vs
`r round(discriminationPerformance[2, ], 3)`) and better cross-validated
calibration (ICI-for benefit `r round(calibrationPerformance[1, ], 4)` vs
`r round(calibrationPerformance[2, ], 4)`). In conclusion, a simpler constant
treatment effect model is adequate for predicting absolute 30-day mortality
benefits of treatment with tPA in patients with with acute MI.


```{r gusto, cache=TRUE, echo=FALSE, fig.cap="Individualized absolute benefit predictions based on baseline risk when using a constant treatment effect approach, a linear interaction approach and RCS smoothing using 3 knots. Risk stratified estimates of absolute benefit are presented within quartiles of baseline risk as reference.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/gusto.tiff")))
# knitr::include_graphics(here::here("figures/gusto.png"))
```

# Discussion

The linear interaction model and the RCS-3 model both displayed very good
performance under many of the considered simulation scenarios. The linear
interaction model was optimal in cases with smaller sample sizes and moderately
performing baseline risk prediction models, that is, it had lower RMSE, was
better calibrated for benefit and had better discrimination for benefit, even in
scenarios with strong quadratic deviations. In scenarios with true non-monotonic
deviations, the linear interaction model was outperformed by RCS-3, especially
in the presence of true treatment-related harms. Increasing the sample size or
the prediction model’s discriminative ability favored RCS-3, especially in
scenarios with non-monotonic deviations and in the presence of treatment-related
harms.

RCS-4 and RCS-5 proved to be too flexible in all considered scenarios, as
indicated by higher RMSE, increased variability of discrimination for benefit
and worse calibration of benefit predictions. Even with larger sample sizes and
strong quadratic or non-monotonic deviations from the base case scenario of
constant relative treatment effects, these more flexible restricted cubic
splines did not outperform the simpler RCS-3. These approaches may only be
helpful if we expect more extreme patterns of heterogeneous treatment effects
compared to the quadratic deviations considered here. Considering interactions
in RCS-3 models as the most complex approach often may be reasonable.

The constant treatment effect model, despite having adequate performance in the
presence of weak treatment effect heterogeneity on the relative scale, quickly
broke down with stronger deviations from constant relative treatment effects. In
these cases, the stratified approach generally had lower error rates compared to
the constant treatment effect model. Such stepwise treatment benefit estimates
are useful for visually demonstrating treatment effect heterogeneity but may be
considered insufficient for making individualized benefit predictions.

Increasing the discriminative ability of the risk model–by increasing the
predictor coefficients of the true risk model–reduced RMSE for all methods. This
increase in discriminative ability translates in higher variability of predicted
risks, which, in turn, allows the considered methods to better capture absolute
treatment benefits. As a consequence, the increase in discriminative ability of
the risk model also led to higher discrimination between those with low or high
benefit (as reflected in values of c-for-benefit). Even though risk model
performance is very important for the ability of risk-based methods to predict
treatment benefit, prediction model development was outside the scope of this
work and has already been studied extensively [@vanKlaveren2019; @Burke2014;
@Abadie2018].

The adaptive approach had adequate performance, following closely on average the
performance of the “true” model in most scenarios. With smaller sample sizes it
tended to miss the treatment-risk interactions and selected simpler models
(Supplement Section 4). This conservative behavior resulted in increased RMSE
variability in these scenarios, especially in the case of true strong linear or
non-monotonic deviations from the base case scenario. Therefore, in the case of
smaller sample sizes the simpler linear interaction model may be a safer choice
for predicting absolute benefits in the presence of any suspected
treatment-related harms.

A limitation of our study is that we assumed treatment benefit
to be a function of baseline risk in the majority of the simulation
scenarios. We also considered constant moderate and strong treatment-related
harms, applied on the absolute scale to expand the range of scenarios in line
with previous work [@Glasziou1995]. In a limited set of scenarios where we
assumed the existence of true treatment-covariate interactions, our conclusions
remained unchanged. Even though the average error rates increased for all the
considered methods, due to the miss-specification of the outcome model, the
linear interaction model had the lowest error rates. RCS-3 had very comparable
performance. The constant treatment effect model often gave biased results,
espcially in the presence of moderate or strong treatment-related harms. All the
results of these simulations can be found in Supplement, Section 7. Future
simulation studies could explore the effect of more extensive deviations from
risk-based treatment effects.

In our simulations we only focused on risk-based methods, using baseline risk as
a reference in a two-stage approach to individualizing benefit
predictions. However, there is a plethora of different methods, ranging from
treatment effect modeling to tree-based approaches available in more recent
literature [@Athey2019; @Lu2018;@Wager2018;@powers2018some]. Many of these
methods rely on incorporating treatment-covariate interactions in the prediction
of benefit. An important caveat of such approaches is that they may be prone to
overfitting, thus exaggerating the magnitude of the predicted benefits. In a
wide range of simulation settings, a simpler risk modeling approach was
consistently better calibrated for benefit compared to more complex treatment
effect modelling approaches [@vanKlaveren2019]. However, whether this remains
the case in a range of empirical settings still needs to be explored Similarly,
when SYNTAX score II, a model developed for identifying patients with complex
coronary artery disease that benefit more from percutaneous coronary
intervention or from coronary artery bypass grafting was redeveloped using fewer
treatment-covariate interactions had better external performance compared to its
predecessor[@farooq2013anatomical; @takahashi2020redevelopment].

In conclusion, the linear interaction approach is a viable option with smaller
sample sizes and/or moderately performing risk prediction models if we consider
a non-constant relative treatment effect plausible. RCS-3 is a better option
when non-monotonic deviations from a constant relative treatment effect and/or
substantial treatment-related harms are anticipated. Increasing the complexity
of the RCS models by increasing the number of knots does not translate to
improved benefit prediction. Using AIC for model selection among the constant
treatment effect, the linear interaction and RCS-3 model is a viable option,
especially with larger sample size.

\newpage
# References
\setlength{\parindent}{-0.25in}
\setlength{\leftskip}{0.25in}
\noindent
<div id="refs"></div>
\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}
\noindent




