---
title: "Models including an interaction of treatment with baseline risk were better able to predict absolute benefit in simulations"
abstract: |
 **Objective:** To compare different risk-based methods predicting individualized treatment effects in RCT simulations. **Study Design and Setting:** We simulated data using diverse assumptions for a baseline prognostic index of risk (PI) and the shape of its intereraction with treatment (none, linear or quadratic). In each sample we predicted absolute benefit using: models with the PI and a constant relative treatment effect; models including an interaction of treatment with the PI; stratification in quarters of the PI; nonlinear transformations of the PI (restricted cubic splines with 3, 4 and 5 knots); an adaptive approach using Akaike’s Information Criterion. We evaluated predictive performance using root mean squared error and measures of discrimination and calibration for benefit. Starting from a base case scenario (sample size 4,250, treatment odds ratio 0.8, AUC of the PI 0.75), we varied the sample size, the treatment effect strength, and the PI's discriminative ability. **Results:** Models including a PI by treatment interaction performed better under most simulation settings. Flexible models required larger sample sizes and higher AUC of the PI to outperform the linear interaction model. The adaptive approach performed similarly to the best-performing method in most scenarios. **Conclusion:** Usually, a model with a linear interaction of the PI with treatment is better able to predict absolute treatment benefit.
authors:
  - name: Alexandros Rekkas
    department: Department of Medical Informatics
    affiliation: Erasmus Medical Center
    location: Rotterdam, The Netherlands
  - name: Peter R. Rijnbeek
    department: Department of Medical Informatics
    affiliation: Erasmus Medical Center
    location: Rotterdam, The Netherlands
  - name: Ewout W. Steyerberg
    department: Department of Biomedical Data Sciences
    affiliation: Leiden University Medical Center
    location: Leiden, The Netherlands
  - name: David van Klaveren
    department: Department of Public Health
    affiliation: Erasmus Medical Center
    location: Rotterdam, The Netherlands
keywords:
  - treatment effect heterogeneity
  - absolute benefit
  - prediction models
output: 
  rticles::arxiv_article:
    keep_tex: true
  bookdown::word_document2:
    reference_docx: reference.docx
geometry: margin=1.0in
date: false
toc: false
font-size: 11pt
header-includes:
  - \renewcommand*\familydefault{\sfdefault}
  - \usepackage{setspace}
  - \usepackage{amsmath}
  - \doublespacing
  - \usepackage[left]{lineno}
  - \usepackage{amssymb}
  - \usepackage{bm}
  - \usepackage{booktabs}
  - \newcommand\given[1][]{\:#1\vert\:}
  - \date{}
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: jce.csl
---


```{r, echo=FALSE, message=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(SmoothHte)
library(rms)

d <- function(x, decimals = 2) {
  sprintf(paste0("%1.", decimals, "f"), x) 
}

knit_hooks$set(
  inline = function(x) {
    prettyNum(
      x,
      big.mark = ",",
      decimal.mark = ".",
      preserve.width = "individual"
    )
  }
)
set.seed(19910930)
```

\linenumbers
# Introduction
Predictive approaches for assessing heterogeneity of treatment effects (HTE) aim
at the development of models predicting either individualized effects or which
of two (or more) treatments is better for an individual [@Varadhan2013]. In
prior work, we divided such methods in three broader categories based on the
reference class used for defining patient similarity when making individualized
predictions or recommendations [@Rekkas2020]. Risk-modeling approaches use
prediction of baseline risk as the reference; treatment effect modeling
approaches also model treatment-covariate interactions, in addition to risk
factors; optimal treatment regime approaches focus on developing treatment
assignment rules and therefore rely heavily on modeling treatment effect
modifiers.

Risk-modeling approaches to predictive HTE analyses provide a viable option in
the absence of well-established treatment effect modifiers [@Kent2019;
@PathEnE]. In simulations, modeling of effect modifiers, i.e.
treatment-covariate interactions, often led to miscalibrated predictions of
benefit, while risk-based methods proved quite robust [@vanKlaveren2019]. Most
often, risk-modeling approaches are carried out in two steps: first a risk
prediction model is developed externally or internally on the entire RCT
population, “blinded” to treatment; then the RCT population is stratified using
this prediction model to evaluate risk-based treatment effect variation
[@Kent2010]. However, even though estimates at the risk subgroup level may be
accurate, these estimated do not apply to individual patients, especially for
patients with predicted risk at the boundaries of the risk intervals. Hence, the
risk-stratified approach is useful for exploring and presenting HTE, but is not
useful for supporting treatment decisions for individual patients.

To individualize treatment effects, the recent PATH statement suggested various
risk-based models including a prognostic index of baseline risk (PI) and
treatment assignment [cite PATH !!]. We aimed to summarize and compare different
risk-based models for predicting individualized treatment effects. We simulated
RCT settings to compare the performance of these models under different
assumptions of the relationship between baseline risk and treatment. We
illustrated the different models by a case study of predicting individualized
effects of tissue plasminogen activator (tPA) versus streptokinase treatment in
patients with an acute myocardial infarction (MI).

# Methods

## Simulation scenarios

For each patient we generated 8 baseline covariates here
$x_1,\dots,x_4\sim N(0, 1)$ and $x_5,\dots,x_8\sim B(1, 0.2)$. Treatment
was allocated using a 50:50 split. Outcomes for patients in the control arm were
generated from a logistic regression model including all baseline covariates. In
the base case scenario coefficient values were such, that the AUC of the
logistic regression model was $0.75$ and the event rate in the control arm was
$20\%$ (Supplement 1).

While binary outcomes in the control arm were generated from Bernoulli variables
with true probabilities $P(y=1|X) = \text{expit}(PI)=\frac{e^{PI}}{1+e^{PI}}$, 
the outcomes in the treatment arm based on true probabilities 
$\text{expit}(lp_1)$, with $$lp_1 = \gamma_2(PI-c)^2 + \gamma_1(PI-c) + \gamma_0$$

The coefficients $\gamma_0,\gamma_1$ and $\gamma_2$ along with the
centering constant $c$ were set for each simulation scenario to mimic a wide
variety scenarios, ranging from true constant relative treatment effect
($\gamma_1=\gamma_2=0$) to moderate and strong linear ($\gamma_2=0$) and
quadratic deviations. We also considered scenarios with treatment-covariate
interactions.
These scenarios include 4 weak interactions
($\text{OR}_{t_x=1} / \text{OR}_{t_x=0}=0.82$), 
4 strong interactions 
($\text{OR}_{t_x=1} / \text{OR}_{t_x=0}=0.61$), 
and 2 weak and 2 strong interactions. Combining all these different settings
resulted in a simulation study of $66$ scenarios. The exact settings for each
scenario are available in the supplementary material.

The sample size of the base case scenario was set to 4,250 ($80%$ power for the
detection of a marginal OR of 0.8). We evaluated the effect of smaller or larger
sample sizes of 1,064 and 17,000, respectively. We also evaluated the of worse
or better discriminative ability for risk, adjusting the baseline covariate
coefficients, such that the AUC of the regression model in the control arm
was 0.65 and 0.85 respectively.

Combining all these settings resulted in a simualation study of 66 scenarios
(exact settings in the supplementary material).

## Individualized risk-based benefit predictions

All methods assume that a risk prediction model is available to assign risk
predictions to individual patients. For the simulations we developed a
prediction model internally, using logistic regression including main effects
for all baseline covariates and treatment assignment. Risk predictions for
individual patients were based on treatment assignment to the control arm, that
is setting treatment assignment to 0.

A *stratified HTE method* has been suggested as an alternative to traditional
subgroup analyses. Patients are stratified into equally-sized risk strata---in
this case based on risk quartiles. Absolute treatment effects within risk strata
are estimated by the difference in event rate between patients in the control
arm and patients in the treated arm. We considered this approach as a reference,
expecting it to perform worse than the other candidates, as its objective is not
to individualize benefit prediction.

Second, we considered a model which assumes *constant relative treatment effect* (constant OR)
Hence, absolute benefit is predicted from
$\hat{\tau}(\bm{x}) = \text{expit}(PI +\log(\text{OR}))$.

Third, we considered a logistic regression model including treatment, the prognostic index, and their interaction. Absolute benefit is then estimated from 
$\hat{\tau}(\bm{x})=\text{expit}(\beta_0+\beta_{PI}PI) - \text{expit}(\beta_0+\beta_{t_x}+(\beta_{PI}+\beta_*)PI)$.
We will refer to this method as the *linear interaction* approach.

Finally, we used *restricted cubic splines* (RCS) to relax the linearity
assumption on the effect of the linear predictor [@Harrell1988]. We considered
splines with 3, 4 and 5 knots to compare models with different levels of
flexibility.

## Evaluation metrics
We evaluated the predictive accuracy of the considered methods by the root mean
squared error (RMSE):

$$\text{RMSE}=\frac{1}{n}\sum_{i=1}^n\big(\tau(\bm{x}_i) - \hat{\tau}(\bm{x}_i)\big)^2$$
We compared the discriminative ability of the methods under study using
c-for-benefit [@vanKlaveren2018]. The c-for-benefit represents the probability
that from two randomly chosen matched patient pairs with unequal observed
benefit, the pair with greater observed benefit also has a higher predicted
benefit. To be able to calculate observed benefit, patients in each treatment
arm are ranked based on their predicted benefit and then matched 1:1 across
treatment arms. *Observed* treatment benefit is defined as the difference of
observed outcomes between the untreated and the treated patient of each matched
patient pair. *Predicted* benefit is defined as the average of predicted benefit
within each matched patient pair.

We evaluated calibration in a similar manner, using the integrated calibration
index (ICI) for benefit [@Austin2019]. The observed benefits are regressed on
the predicted benefits using a locally weighted scatterplot smoother (loess).
The ICI-for-benefit is the average absolute difference between predicted and
smooth observed benefit. Values closer to $0$ represent better calibration.


# Results

## Simulations

The model including a constant relative treatment effect had the lowest median
RMSE in scenarios with a true constant relative treatment effect (OR = 0.8, N =
`r 4250` and AUC = 0.75) or with moderate relative deviations (Figure
\ref{fig:rmsebase}; Panel A). However, when we considered strong linear and
quadratic deviations from a constant relative treatment effect the linear
interaction model performed best (Figure \ref{fig:rmsebase}; Panels B and C).
Only in the case of strong quadratic deviations models including RCS (3 knots)
performed equally well to the linear interaction method. Increasing the number
of knots in RCS resulted in higher RMSE across all scenarios. The adaptive
approach performed very similarly to the best performing model in each scenario.

```{r rmsebase, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated superpopulation of size 500,000. \\textit{Panel A} presents the results of the scenario with true constant relative treatment effect, with a true prediction AUC of 0.75 and sample size of 4250; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effects; \\textit{Panel C} presents the results for strong linear deviations from constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations from constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/rmse_base.png"))
```

When we increased the sample size (N = `r 17000`), the model including a
constant relative treatment effect had the lowest RMSE under the assumption of
true constant relative treatment effects (Figure \ref{fig:rmsesamplesize};
Panel A). However, when introducing moderate and strong linear deviations the
linear interaction model outperformed the constant treatment
effect model (Figure \ref{fig:rmsesamplesize}; Panels B and C). Furthermore, the
linear interaction model was outperformed by the more flexible RCS models (3
knots) in the case of strong quadratic deviations. Again, the increased
flexibility of RCS smoothing with higher number of knots resulted in overfitting
and worse predictive accuracy (Figure \ref{fig:rmsesamplesize}; Panel D).

```{r rmsesamplesize, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated sample of size 500,000. \\textit{Panel A} presents the results under the base case scenario of true constant relative treatment effect, with a true prediction AUC of 0.75 and sample size of 17,000; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effects; \\textit{Panel C} presents the results for strong linear deviations from constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/rmse_sample_size.png"))
```

When we increased the AUC of the true prediction model to 0.85, models including
RCS smoothing had the lowest RMSE in the presence of strong quadratic deviations
from the base case of true constant relative treatment effects (Figure
\ref{fig:rmseauc}; Panel D). However, with milder deviations, the linear
interaction model had the lowest RMSE with the RCS smoothing methods (3 knots)
being a close second (Figure \ref{fig:rmseauc}; Panels B and C). Increasing the
number of knots of RCS smoothing resulted in increased RMSE, which was less
pronounced in the case of strong quadratic deviations.

```{r rmseauc, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated sample of size 500,000. \\textit{Panel A} presents the results under the base case scenario of true constant relative treatment effect, with a true prediction AUC of 0.85 and sample size of 4,250; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effects, while holding true prediction AUC and sample size constant; \\textit{Panel C} presents the results for strong linear deviations from constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations from constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/rmse_auc.png"))
```

The constant effects model, the linear interaction model and models with RCS
smoothing (3 knots) had the highest median c-for-benefit in the base case
scenario and the scenarios where linear and quadratic deviations were
considered. The constant treatment effect model and the linear interaction model
tended to present much lower variability compared to all other approaches
(Figure \ref{fig:discrimination}). With increasing number of RCS knots, we
observed decreasing median values and increasing variability of the
c-for-benefit in all scenarios.

```{r discrimination, echo=FALSE, fig.cap="Discrimination for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. \\textit{Panel A} presents the results under the base case scenario of true constant relative treatment effect, with a true prediction AUC of 0.75 and sample size of 4250; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effects; \\textit{Panel C} presents the results for strong linear deviations from constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations from constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/discrimination_base.png"))
```

As for calibration, the linear interaction model had the lowest median
ICI-for-benefit in the majority of scenarios except for the scenarios where no
or moderate linear deviations from the base case were considered. In that case
constant treatment effect models demonstrated optimal calibration, very
comparable to the linear interaction model's performance, nonetheless (Figure
\ref{fig:calibration}). With strong linear or quadratic deviations, the
constant treatment effect model was poorly calibrated (Figure
\ref{fig:calibration}; Panels C and D).

```{r calibration, echo=FALSE, fig.cap="Calibration for benefit of the considered methods across 500 replications calculated in a simulated sample of size 500,000. \\textit{Panel A} presents the results under the base case scenario of true constant relative treatment effect, with a true prediction AUC of 0.75 and sample size of 4250; \\textit{Panel B} presents the results under moderate linear deviations from constant treatment effectst; \\textit{Panel C} presents the results for strong linear deviations from of constant relative treatment effects; \\textit{Panel D} presents the results for strong quadratic deviations from constant relative treatment effects.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/calibration_base.png"))
```

## Case study
```{r, echo=FALSE, warning=FALSE, message=FALSE}
load(here::here("data/raw/gusto.rda"))
gusto <- gusto %>%
  tibble() %>%
  filter(!is.na(tpa))

treatmentArms <- gusto %>%
  group_by(tpa) %>%
  summarise(n = n())
```

We demonstrate the different methods for individualizing treatment benefits
using data from `r nrow(gusto)` patients with an acute myocardial infarction
(MI) included in the GUSTO-I trial.
`r treatmentArms %>% filter(tpa == 1) %>% select(n)` patients were randomized to
tissue plasminogen activator (tPA) treatment and
`r treatmentArms %>% filter(tpa == 0) %>% select(n)` were randomized to
streptokinase. The outcome of interest was 30-day mortality, recorded for all
patients.

In line with previous analyses [@Califf1997; @Steyerberg2000], we fitted a logistic regression
model with 6 baseline covariates, i.e. age, Killip class, systolic blood
pressure, heart rate, an indicator of previous MI, and the location of MI, to
predict 30-day mortality risk. A constant effect of treatment was included in
the model. When deriving risk predictions for individuals we set the treatment
indicator to 0. More information on model development can be found in the
supplement.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
gusto <- gusto %>%
  tibble() %>%
  rename(
    "outcome" = "day30",
    "treatment" = "tpa"
  )

prediction <- lrm(
  outcome ~ treatment + age + Killip + pmin(sysbp, 120) + lsp(pulse, 50) + pmi + miloc,
  data = gusto,
  maxit = 99
)



riskLinearPredictor <- predict(
  prediction,
  newdata = gusto %>% mutate(treatment = 0) %>% data.frame()
)

gusto <- gusto %>%
  mutate(
    riskLinearPredictor = riskLinearPredictor
  )

folds <- caret::createFolds(gusto$outcome, k = 4)

evaluatePerformance <- function(data, testRows, settings) {
  isStratified <- FALSE
  if ("modelBased" %in% class(settings)) {
    model <- fitModelBasedHte(data %>% dplyr::slice(-testRows), settings)
    tmp <- data %>%
      slice(testRows) %>%
      dplyr::mutate(
        predictedBenefit = predictBenefitModelBasedHte(
          p             = plogis(.$riskLinearPredictor), 
          modelBasedFit = model
        )
      )
    
  } else if ("rcs" %in% class(settings)) {
    model <- fitRcsHte(data %>% dplyr::slice(-testRows), settings)
    tmp <- gusto %>%
      slice(testRows) %>%
      dplyr::mutate(
        predictedBenefit = predictSmoothBenefit(
          p          = plogis(riskLinearPredictor), 
          smoothFit  = model
        )
      )
  } else if ("stratified" %in% class(settings)) {
    isStratified <- TRUE
    model <- fitStratifiedHte(data %>% dplyr::slice(-testRows), settings)
    tmp <- gusto %>%
      slice(testRows) %>%
      dplyr::mutate(
        predictedBenefit = predictStratifiedBenefit(
          p          = plogis(riskLinearPredictor), 
          stratifiedHte  = model
        )
      )
  }
  cForBenefit <- calculateCForBenefit(tmp)
  iciForBenefit <- calculateCalibrationForBenefit(tmp)
  aic <- ifelse(
    isStratified,
    NA,
    model$aic
  )
  
  return(
    list(
      c = cForBenefit,
      ici = iciForBenefit$ici,
      aic = aic
    )
  )
}


constant <- lapply(
  folds,
  evaluatePerformance,
  data = gusto,
  settings = createModelBasedSettings(type = "treatment")
)

constantData <- do.call(bind_rows, constant)
cConstant <- mean(constantData$c)
iciConstant <- mean(constantData$ici)
aicConstnat <- mean(constantData$aic)

stratified <- lapply(
  folds,
  evaluatePerformance,
  data = gusto,
  settings = createStratifiedSettings()
)

stratifiedData <- do.call(bind_rows, stratified)
cStratified <- mean(stratifiedData$c)
iciStratified <- mean(stratifiedData$ici)


linear <- lapply(
  folds,
  evaluatePerformance,
  data = gusto,
  settings = createModelBasedSettings()
)

linearData <- do.call(bind_rows, linear)
clinear <- mean(linearData$c)
iciLinear <- mean(linearData$ici)
aicLinear <- mean(linearData$aic)


rcs3 <- lapply(
  folds,
  evaluatePerformance,
  data = gusto,
  settings = createRcsSettings(nKnots = 3)
)

rcs3Data <- do.call(bind_rows, rcs3)
cRcs3    <- mean(rcs3Data$c)
iciRcs3  <- mean(rcs3Data$ici)
aicRcs3  <- mean(rcs3Data$aic)


rcs4 <- lapply(
  folds,
  evaluatePerformance,
  data = gusto,
  settings = createRcsSettings(nKnots = 4)
)

rcs4Data <- do.call(bind_rows, rcs4)
cRcs4    <- mean(rcs4Data$c)
iciRcs4  <- mean(rcs4Data$ici)
aicRcs4  <- mean(rcs4Data$aic)


rcs5 <- lapply(
  folds,
  evaluatePerformance,
  data = gusto,
  settings = createRcsSettings(nKnots = 5)
)

rcs5Data <- do.call(bind_rows, rcs5)
cRcs5    <- mean(rcs5Data$c)
iciRcs5  <- mean(rcs5Data$ici)
aicRcs5  <- mean(rcs5Data$aic)

gustoPerformance <- tibble(
  discrimination = c(
    cConstant, clinear, cRcs3,
    cRcs4, cRcs5
  ),
  calibration = c(
    iciConstant, iciLinear, iciRcs3,
    iciRcs4, iciRcs5
  ),
  aic = c(
    aicConstnat, aicLinear, aicRcs3,
    aicRcs4, aicRcs5
  ),
  method = c(
    "constant treatment effect",
    "linear interaction",
    "RCS smoothing with 3 knots",
    "RCS smoothing with 4 knots",
    "RCS smoothing with 5 knots"
  )
)

discriminationPerformance <- gustoPerformance %>%
  slice(c(2, 3)) %>%
  select(discrimination)

calibrationPerformance <- gustoPerformance %>%
  slice(c(2, 3)) %>%
  select(calibration)

```

We used the risk linear predictor to fit the proposed methods under study for
individualizing absolute benefit predictions. All methods predicted increasing
benefits for patients with higher baseline risk predictions, but the fitted
patterns were clearly different. The adaptive approach selected the model with
RCS smoothing with 4 knots. However, for very low baseline risk this model
predicted decreasing benefit with increasing risk may be somewhat too flexible.
The more robust models, the linear interaction model or the model with RCS
smoothing (3 knots), gave very similar benefit predictions, followed the
evolution of the stratified estimates very closely and may therefore be
preferable for use in clinical practice. The model with RCS smoothing (3 knots)
had somewhat lower AIC compared to the linear interaction model, slightly better
cross-validated discrimination (c-for-benefit
`r round(discriminationPerformance[2, ], 3)` vs
`r round(discriminationPerformance[1, ], 3)`) and quite similar cross-validated
calibration (ICI-for benefit `r round(calibrationPerformance[2, ], 4)` vs
`r round(calibrationPerformance[1, ], 4)`).


```{r gusto, echo=FALSE, fig.cap="Individualized absolute benefit predictions based on baseline risk when using a constantn treatment effect approach, a linear interaction approach and RCS smoothing using 3,4 and 5 knots. Risk stratified estimates of absolute benefit are presented within quartiles of baseline risk as reference.", fig.show="hold", out.width = '100%'}
knitr::include_graphics(here::here("figures/gusto.png"))
```

# Discussion

The linear interaction model proved to be superior to alternative approaches
when predicting risk-based treatment benefit under a wide range of scenarios. It
generally had lower mean squared error, lower e-for-benefit and higher
c-for-benefit with lower variability across simulation replications. Models
including restricted cubic splines with 3 knots only outperformed the linear
interaction model in the presence of strong quadratic deviations from a constant
relative treatment effect.

Including restricted cubic splines with 4 or 5 knots proved to be too flexible,
as indicated by higher RMSE, increased variability of discrimination for benefit
and worse calibration of benefit predictions. Even with larger sample sizes and
strong quadratic deviations from the base case scenario of constant relative
treatment effects, these more flexible restricted cubic splines did not
outperform the simpler RCS with 3 knots. These more flexible approaches may only
be helpful if we expect more extreme patterns of heterogeneous treatment
effects.

The constant treatment effect model, despite having adequate performance in the
presence of weak treatment effect heterogeneity on the relative scale, quickly
broke down with stronger deviations from constant relative treatment effects. In
these cases, the stratified approach generally had lower error rates compared to
the constant treatment effect model. Stepwise treatment benefit estimates are
very useful for demonstrating treatment effect heterogeneity--because
estimating treatment effect requires groups of patients rather than individual
patients--but are not helpful for making individualized absolute benefit
predictions.

Increasing the discriminative ability of the risk model – by increasing the
predictor coefficients of the true risk model – reduced RMSE for all methods.
This increase in discriminative ability translates in higher variability of
predicted risks, which, in turn, allows the considered methods to better capture
absolute treatment benefits. As a consequence, the increase in discriminative
ability of the risk model also led to higher values of c-for-benefit. Even
though risk model performance is very important for the ability of risk-based
methods to predict treatment benefit, prediction model development was outside
the scope of this work and has already been studied extensively
[@vanKlaveren2019; @Burke2014; @Abadie2018].

Risk-based approaches to predictive HTE estimate treatment benefit as a function
of baseline risk. A limitation of our study is that we assumed treatment benefit
to be a function of baseline risk in the majority of the simulation scenarios.
Nevertheless, our main conclusions did not change when we generated individual
treatment-covariate interactions (supplementary table/figure x). Future
simulation studies could explore the effect of more extensive deviations from
risk-based treatment effects.

Recent years have seen an increased interest in predictive HTE approaches
focusing on individualized benefit predictions. In our simulations we only
focused on risk-based methods, using baseline risk as a reference in a two-stage
approach to individualizing benefit predictions. However, there is a plethora of
different methods, ranging from treatment effect modeling to tree-based
approaches available in more recent literature [@Athey2019; @Lu2018;
@Wager2018]. Simulations are also needed to assess relative performance and
define the settings where these break down or outperform each other.

In conclusion, when comparing different risk-based approaches to predict
individualizing benefit a models including a linear treatment interaction with
the prognostic performed best in a wide range of scenarios. More flexible models
with restricted cubic splines required larger sample sizes and higher AUC of the
PI to outperform the linear model. An adaptive approach, selecting the model
with optimal AIC, had comparable performance to the best performing approach in
most of the scenarios.


\newpage
# References
\nolinenumbers
\setlength{\parindent}{-0.25in}
\setlength{\leftskip}{0.25in}
\noindent
<div id="refs"></div>
\setlength{\parindent}{0in}
\setlength{\leftskip}{0in}
\noindent
