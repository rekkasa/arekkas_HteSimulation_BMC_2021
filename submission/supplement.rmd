---
title: "Supplementary material"
output:
    bookdown::pdf_document2: default
geometry: margin=1.0in
toc: false
font-size: 12pt
header-includes:
  - \usepackage{amssymb}
  - \usepackage{bm}
  - \usepackage{booktabs}
  - \newcommand{\beginsupplement}{\setcounter{table}{0}  \renewcommand{\thetable}{S\arabic{table}} \setcounter{figure}{0} \renewcommand{\thefigure}{S\arabic{figure}}}
  - \newcommand\given[1][]{\:#1\vert\:}
editor_options: 
  chunk_output_type: console
bibliography: references.bib
csl: jce.csl
---

```{r, echo=FALSE, message=FALSE, include=FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
library(here)

d <- function(x, decimals = 2) {
  sprintf(paste0("%1.", decimals, "f"), x) 
}
knit_hooks$set(
  inline = function(x) {
    prettyNum(
      x,
      format = "f",
      big.mark = ",",
      decimal.mark = ".",
      preserve.width = "individual"
    )
  }
)
```

\beginsupplement

# Simulation settings
For all patients we observe covariates $x_1,\dots,x_8$, of which $4$ are
continuous and $4$ are binary. More specifically,

\begin{equation*}
x_1,\dots,x_4 \sim N(0, 1)
\end{equation*}
\begin{equation*}
x_5,\dots,x_8 \sim B(1, 0.2)
\end{equation*}

We first, generate the binary outcomes $y$ for the untreated patients ($t_x=0$), based on 

\begin{equation} 
P(y\given \bm{x}, t_x=0) = g(\beta_0 + \beta_1x_1+\dots+\beta_8x_8) = g(lp_0),
(\#eq:p0)
\end{equation}

where $$g(x) = \frac{e^x}{1+e^x}$$

For treated patients, outcomes are generated from:

\begin{equation}
P(y\given\bm{x}, t_x=1) = g(lp_1)
(\#eq:p1)
\end{equation}


where $$lp_1 = \gamma_2(lp_0-c)^2+\gamma_1(lp_0-c)+\gamma_0$$

## Base-case scenario
The base-case scenario assumes a constant odds ratio of $0.8$ in favor
of treatment. The simulated datasets are of size $n=4250$, where
treatment is allocated at random using a 50/50 split (80% power for
the detection of an unadjusted OR of 0.8, assuming an event rate of
20% in the untreated arm). Outcome incidence in the untreated
population is set at $20\%$. For the development of the prediction
model we use the model defined in \@ref(eq:p0) including a constant
treatment effect. When doing predictions, $t_x$ is set to $0$. The
value of the true $\bm{\beta}$ is such that the above prediction model
has an AUC of $0.75$.


The previously defined targets are achieved when $\bm{\beta}=(-2.08,
0.49,\dots,0.49)^t$. For the derivations in the treatment arm we use
$\bm{\gamma}=(\log(0.8), 1, 0)^t$.

## Deviations from base-case
We deviate from the base-case scenario in two ways. First, we alter
the overall target settings of sample size, overall treatment effect
and prediction model AUC. In a second stage, we consider settings that
violate the assumption of a constant relative treatment effect, using
a model-based approach.

For the first part, we consider:

* Sample size:
  + $n=1064$
  + $n=17000$
* Overall treatment effect:
  + $OR=0.5$
  + $OR=1$
* Prediction performance:
  + $AUC=0.65$
  + $AUC=0.85$
  
We set the true risk model coefficients to be $\bm{\beta} = \big(-1.63, 0.26,\dots,0.26\big)^t$ for $AUC=0.65$ and $\bm{\beta} = \big(-2.7, 0.82,\dots,0.82\big)^t$ for $AUC=0.85$. In both cases, $\beta_0$ is selected so that an event rate of $20\%$ is maintained in the control arm.

For the second part linear, quadratic and non-monotonic deviations
from the assumption of constant relative effect are considered. We
also consider different intensity levels of these deviations. Finally,
constant absolute treatment-related harms are introduced,
i.e. positive ($0.25\times\text{true average benefit}$), strong
positive ($0.50\times\text{true average benefit}$) and negative
($-0.25\times\text{true average benefit}$; i.e. constant absolute
treatment-related benefit). In case of true absent treatment effects,
treatment-related harms are set to $1\%, 2\%$ and $-1\%$ for
positive, strong positive and negative setting, respectively. The
settings for these deviations are defined in Table \@ref(tab:tab1).

## Risk modeling
Merging treatment arms, we develop prediction models including a constant relative treatment effect:

\begin{equation}
E\{y\given x,t_x\} = P(y\given x, t_x) = g(\beta_0+\beta_1x_1+\dots+\beta_8x_8+\gamma t_x)
\end{equation}
(\#eq:risk)
Individualized predictions are derived setting $t_x=0$.

## Approaches to individualize benefit predictions

### Risk stratification
Derive a prediction model using the same approach as above and divide
the population in equally sized risk-based subgroups. Estimate
subgroup-specific absolute benefit from the observed absolute
differences. Subject-specific benefit predictions are made by
attributing to individuals their corresponding subgroup-specific
estimate.

### Constant treatment effect
Assuming a constant relative treatment effect, fit the adjusted model
in \@ref(eq:risk). Then, an estimate of absolute benefit can be
derived from$$\hat{f}_{\text{benefit}}(lp\given \bm{x},
\hat{\bm{\beta}}) = g(lp) - g(lp+\hat{\gamma}) $$

### Linear interaction
The assumption of constant relative treatment effect is relaxed
modeling a linear interaction of treatment with the risk linear
predictor: $$E\{y\given \bm{x}, t_x, \hat{\bm{\beta}}\} =
g\big(lp+(\gamma_0+\gamma_1lp)t_x\big)$$ We predict absolute benefit
from $$\hat{f}_{\text{benefit}}(lp\given\bm{x}, \hat{\bm{\beta}}) =
g(lp) - g\big(\gamma_0+(1+\gamma_1)lp\big)$$

### Restricted cubic splines
Finally, we drop the linearity assumption and predict absolute benefit using
smoothing with restricted cubic splines with 3, 4, and 5 knots. More
specifically, we fit the model:

$$P(y=1\given lp, t_x) = g\big(\beta_0+\beta_{t_x}t_x+f_{RCS}(lp) + f_{RCS}(lp)\times t_x\big)$$
where
$$f_{RCS}(x)=\alpha_0+\alpha_1h_1(x)+\alpha_2h_2(x)+\dots+\alpha_{k-1}h_{k-1}(x)$$ with
$$h_{j+1}(x)= (x-t_j)^3-(x-t_{k-1})_+\frac{t_k-t_j}{t_k-t_{k-1}}+(x-t_k)^3_+\frac{t_{k-1}-t_j}{t_k-t_{k-   1}}$$
and $t_1,\dots,t_k$ are the selected knots. We predict absolute benefit from $$\hat{f}_{\text{benefit}}(lp \given \bm{x},\hat{\bm{\beta}})=P(y=1\given lp, t_x=0)-P(y=1\given lp,t_x=1)$$.


```{r tab1, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE}
 asd <- read_csv(
  here("data/processed/analysisIds.csv")
) %>%
  select(-"type")
kableExtra::kbl(
  asd,
  format = "latex",
  escape = FALSE,
  longtable   = TRUE,
  align       = "r",
  booktabs    = TRUE,
  caption     = "Scenario settings of the entire simulation study.",
  col.names   = c(
    "Scenario",
    "Base",
    "N",
    "AUC",
    "Treatment-related harm",
    paste0("b", 0:8),
    paste0("g", 0:2),
    "c",
    "Before harms",
    "After harms"
  ),
  linesep = c('', '', '', '\\addlinespace'),
  digits      = 2,
  format.args = list(
    big.mar      = ",",
    decimal.mark = "."
  )
) %>%
  kableExtra::landscape() %>%
  kableExtra::add_header_above(
    c(
      "Analysis ID"           = 5,
      "Baseline risk"         = 9,
      "True treatment effect" = 4,
      "Benefit"               = 2
      )
  ) %>%
  kableExtra::kable_styling(font_size = 7)
```

# Adaptive model selection frequencies

```{r adaptiveBase, cache=TRUE, echo=FALSE, fig.cap="Model selection frequencies of the adaptive approach based on Akaike's Information Criterion across 500 replications. The scenario with the true constant relative treatment effect (first panel) had a true prediction AUC of 0.75 and sample size of 4,250. ", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/selected_model_adaptive_base.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```

```{r adaptiveSampleSize, cache=TRUE, echo=FALSE, fig.cap="Model selection frequencies of the adaptive approach based on Akaike's Information Criterion across 500 replications. Sample size is 17,000 rather than 4,250 in Figure \\ref{fig:adaptiveBase}", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/selected_model_adaptive_sample_size.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```

```{r adaptiveAuc, cache=TRUE, echo=FALSE, fig.cap="Model selection frequencies of the adaptive approach based on Akaike's Information Criterion across 500 replications. AUC is 0.85 rather than 0.75 in Figure \\ref{fig:adaptiveBase}", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/selected_model_adaptive_auc.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```

\newpage

# Discrimination and calibration for benefit

```{r discriminationSampleSize, cache=FALSE, echo=FALSE, fig.cap="Sample size", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/discrimination_moderate_sample_size.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```


```{r discriminationAuc, cache=FALSE, echo=FALSE, fig.cap="Auc", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/discrimination_moderate_auc.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```

```{r calibrationSampleSize, cache=FALSE, echo=FALSE, fig.cap="Calibration Sample size", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/calibration_moderate_sample_size.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```


```{r calibrationAuc, cache=FALSE, echo=FALSE, fig.cap="Calibration Auc", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/calibration_moderate_auc.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```

\newpage

# Strong relative treatment effect

Here we present the root mean squared error of the considered methods
using strong constant relative treatment effect ($\text{OR}=0.5$) as
the reference. Again, the same sample size and prediction performance
settings were considered along with the same settings for linear,
quadratic and non-monotonic deviations from the base case scenario of
constant relative treatment effects are considered. All results can be found at [https://arekkas.shinyapps.io/simulation_viewer/](https://arekkas.shinyapps.io/simulation_viewer/).

```{r rmseHighBase, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replications calculated in a simulated super-population of size 500,000. The scenario with true constant relative treatment effect (panel A) had a true prediction AUC of 0.75 and sample size of 4,250. The RMSE is also presented for strong linear (panel B), strong quadratic (panel C), and non-monotonic (panel D) deviations from constant relative treatment effects. Panels on the right side present the true relationship between baseline risk (x-axis) and absolute treatment benefit (y-axis). The 2.5, 25, 75 and 97.5 percentiles of the risk distribution are expressed in the boxplot.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_high_base.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```

```{r rmseHighSampleSize, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replcations calculated in a simulated sample of size 500,000. Sample size is 17,000 rather than 4,250 in Figure \\ref{fig:rmseHighBase}.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_high_sample_size.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```

```{r rmseHighAuc, cache=TRUE, echo=FALSE, fig.cap="RMSE of the considered methods across 500 replcations calculated in a simulated sample of size 500,000. AUC is 0.85 rather than in Figure \\ref{fig:rmseHighBase}.", fig.show="hold", out.width = '100%'}
grid::grid.raster(tiff::readTIFF(here("figures/rmse_high_auc.tiff")))
# knitr::include_graphics(here::here("figures/calibration_base.png"))
```
